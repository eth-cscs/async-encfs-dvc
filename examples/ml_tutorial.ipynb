{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e1e3f1f-753d-462b-88bd-b31d918896c1",
   "metadata": {},
   "source": [
    "# Tutorial: Building a DVC repo for an ML workflow\n",
    "\n",
    "This guide demonstrates the construction of a DVC repository that is tailored to a machine learning pipeline with infrastructure-as-code principles. The example pipeline will perform dataset preprocessing and machine learning training/inference stages. The key concepts we will explore include:\n",
    "\n",
    " * Repository-wide configuration, managed via repo-policies\n",
    " * Stage-wise configuration, controlled through stage-policies\n",
    " * The creation of an app-policy that derives its parameters from the previous two, leading to a concrete instantiation of the corresponding DVC stages\n",
    "\n",
    "It is important to note that stage and app policies cover multiple logically connected DVC stages, not just a single stage.  For example, a machine learning app policy usually encapsulates both a training and inference stage of an ML model.\n",
    "\n",
    "In the context of an ML workflow, we'll cover how to\n",
    " * Handle manual and automated preprocessing steps in DVC\n",
    " * Set up an ML stage using these techniques\n",
    " * Execute the stages\n",
    "\n",
    "To streamline this tutorial, we will not be using `EncFS`, containers and SLURM. The focus will primarily be on the stage and app policies as well as on the file hierarchy. All additional features can conveniently be activated later via modifications to the app policy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f276f6c3-08cf-409b-b1e3-6e767e0e82db",
   "metadata": {},
   "source": [
    "## Initializing the DVC repository\n",
    "We first import the depencies for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af8552e-1d3e-4c31-b410-627b1de89fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac94128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG  # test_ml_tutorial: skip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65be096-eb8e-4d18-a2e2-858ea136b47b",
   "metadata": {},
   "source": [
    "Create a new directory `data/v0` for the DVC root and change to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6dd315e-6ab4-4e75-8a85-4056b09563ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data/v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5823a232-0796-405f-af6d-ecda49add286",
   "metadata": {},
   "source": [
    "Initialize a `plain` DVC repository using the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "878f12d8-3b44-40f4-8bd2-ffb2dd84fa2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-07-25 15:22:22,253\u001b[39m \u001b[34mDEBUG\u001b[39m: v0.1.dev8866+gd72e04c, CPython 3.8.10 on Linux-5.15.0-76-generic-x86_64-with-glibc2.29\n",
      "\u001b[34m2023-07-25 15:22:22,253\u001b[39m \u001b[34mDEBUG\u001b[39m: command: /home/lukasd/src/mitraccel/async-encfs-dvc/venv/bin/dvc init --subdir --verbose\n",
      "\u001b[34m2023-07-25 15:22:22,494\u001b[39m \u001b[34mDEBUG\u001b[39m: Added '/home/lukasd/src/mitraccel/async-encfs-dvc/examples/data/v0/.dvc/config.local' to gitignore file.\n",
      "\u001b[34m2023-07-25 15:22:22,495\u001b[39m \u001b[34mDEBUG\u001b[39m: Added '/home/lukasd/src/mitraccel/async-encfs-dvc/examples/data/v0/.dvc/tmp' to gitignore file.\n",
      "\u001b[34m2023-07-25 15:22:22,495\u001b[39m \u001b[34mDEBUG\u001b[39m: Added '/home/lukasd/src/mitraccel/async-encfs-dvc/examples/data/v0/.dvc/cache' to gitignore file.\n",
      "\u001b[34m2023-07-25 15:22:22,495\u001b[39m \u001b[34mDEBUG\u001b[39m: Removing '/var/tmp/dvc/repo/2ee751a7fb5029083b3bccfd7ff622fb'\n",
      "\u001b[34m2023-07-25 15:22:22,520\u001b[39m \u001b[34mDEBUG\u001b[39m: Staging files: {'/home/lukasd/src/mitraccel/async-encfs-dvc/examples/data/v0/.dvc/.gitignore', '/home/lukasd/src/mitraccel/async-encfs-dvc/examples/data/v0/.dvcignore', '/home/lukasd/src/mitraccel/async-encfs-dvc/examples/data/v0/.dvc/config'}\n",
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "\u001b[34m2023-07-25 15:22:22,527\u001b[39m \u001b[34mDEBUG\u001b[39m: Analytics is enabled.\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m        DVC has enabled anonymous aggregate usage analytics.         \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m     Read the analytics documentation (and how to opt-out) here:     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m             <\u001b[36mhttps://dvc.org/doc/user-guide/analytics\u001b[39m>              \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\n",
      "\u001b[33mWhat's next?\u001b[39m\n",
      "\u001b[33m------------\u001b[39m\n",
      "- Check out the documentation: <\u001b[36mhttps://dvc.org/doc\u001b[39m>\n",
      "- Get help and share ideas: <\u001b[36mhttps://dvc.org/chat\u001b[39m>\n",
      "- Star us on GitHub: <\u001b[36mhttps://github.com/iterative/dvc\u001b[39m>\n",
      "\u001b[34m2023-07-25 15:22:22,528\u001b[39m \u001b[34mDEBUG\u001b[39m: Analytics is enabled.\n",
      "\u001b[34m2023-07-25 15:22:22,555\u001b[39m \u001b[34mDEBUG\u001b[39m: Trying to spawn '['daemon', '-q', 'analytics', '/tmp/tmphhc8307u']'\n",
      "\u001b[34m2023-07-25 15:22:22,556\u001b[39m \u001b[34mDEBUG\u001b[39m: Spawned '['daemon', '-q', 'analytics', '/tmp/tmphhc8307u']'\n",
      "\u001b[0m\u001b[0mInitialized DVC repo (plain) and stage policies.\n"
     ]
    }
   ],
   "source": [
    "!dvc_init_repo . plain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6e1e70-9135-4c7c-954f-af0c5b850341",
   "metadata": {},
   "source": [
    "The DVC repo has been initialized with repo and stage policies available under `.dvc_policies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d25ced6-1813-4891-895a-8963bb46a96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.dvc_policies\u001b[00m\n",
      "├── \u001b[01;34mrepo\u001b[00m\n",
      "│   └── dvc_root.yaml\n",
      "└── \u001b[01;34mstages\u001b[00m\n",
      "    ├── dvc_config.yaml\n",
      "    ├── dvc_etl.yaml\n",
      "    ├── dvc_in.yaml\n",
      "    ├── dvc_ml_inference.yaml\n",
      "    ├── dvc_ml_training.yaml\n",
      "    └── dvc_simulation.yaml\n",
      "\n",
      "2 directories, 7 files\n"
     ]
    }
   ],
   "source": [
    "!tree .dvc_policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c1eae6-bdeb-491c-a3dc-1d8ae82b6e6c",
   "metadata": {},
   "source": [
    "## Establishing the input dataset\n",
    "Our pipeline will be based on a dataset labeled `ml_dataset` that we assume to be split into training, test, and inference. Each of these has specific subsets and we will utilize a subset labeled `ex1` for all of them (although this could be chosen differently for each of them). We populate the repository with this input data and track it with DVC by executing the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61fa28d0-9aa6-4847-aa0d-53f40385ccba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25l⠋ Checking graph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add .gitignore ex1.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "/home/lukasd/src/mitraccel/async-encfs-dvc/examples/data/v0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25l⠋ Checking graph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add ex1.dvc .gitignore\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "/home/lukasd/src/mitraccel/async-encfs-dvc/examples/data/v0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25l⠋ Checking graph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add ex1.dvc .gitignore\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "/home/lukasd/src/mitraccel/async-encfs-dvc/examples/data/v0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25h\r"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir -p in/ml_dataset_v1/{training,test,inference}/original/ex1\n",
    "touch in/ml_dataset_v1/{training,test,inference}/original/ex1/in.dat\n",
    "for d in in/ml_dataset_v1/{training,test,inference}/original; do\n",
    "    cd $d && dvc add ex1 && cd -\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525a331d-ac6d-464a-805f-9ce38de6222e",
   "metadata": {},
   "source": [
    "The resulting file hierarchy looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "102870a6-3156-4b36-b72e-b368dca773e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34min\u001b[00m\n",
      "└── \u001b[01;34mml_dataset_v1\u001b[00m\n",
      "    ├── \u001b[01;34minference\u001b[00m\n",
      "    │   └── \u001b[01;34moriginal\u001b[00m\n",
      "    │       ├── \u001b[01;34mex1\u001b[00m\n",
      "    │       │   └── in.dat\n",
      "    │       └── ex1.dvc\n",
      "    ├── \u001b[01;34mtest\u001b[00m\n",
      "    │   └── \u001b[01;34moriginal\u001b[00m\n",
      "    │       ├── \u001b[01;34mex1\u001b[00m\n",
      "    │       │   └── in.dat\n",
      "    │       └── ex1.dvc\n",
      "    └── \u001b[01;34mtraining\u001b[00m\n",
      "        └── \u001b[01;34moriginal\u001b[00m\n",
      "            ├── \u001b[01;34mex1\u001b[00m\n",
      "            │   └── in.dat\n",
      "            └── ex1.dvc\n",
      "\n",
      "10 directories, 6 files\n"
     ]
    }
   ],
   "source": [
    "!tree in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c3900-edd2-4cb0-8fb1-1fcba605624a",
   "metadata": {},
   "source": [
    "Before moving to the definition of preprocessing stages, we define execution labels based on timestamps for the subsequent DVC stages. In a real-world application, the timestamps would usually be generated on the fly when creating the DVC stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cae5a9cc-eee6-4c68-b9fe-46e195a0619c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: ETL_TRAIN_RUN_LABEL=ex1-20230713-083624\n",
      "env: ETL_INF_RUN_LABEL=ex1-20230713-083812\n",
      "env: ETL_TEST_RUN_LABEL=ex1-20230713-083951\n",
      "env: ML_TRAIN_RUN_LABEL=ex1-20230713-090119\n",
      "env: ML_INF_RUN_LABEL=ex1-20230713-121007\n"
     ]
    }
   ],
   "source": [
    "%env ETL_TRAIN_RUN_LABEL=ex1-20230713-083624\n",
    "%env ETL_INF_RUN_LABEL=ex1-20230713-083812\n",
    "%env ETL_TEST_RUN_LABEL=ex1-20230713-083951\n",
    "%env ML_TRAIN_RUN_LABEL=ex1-20230713-090119\n",
    "%env ML_INF_RUN_LABEL=ex1-20230713-121007"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b9e318-748a-4d20-a90b-f352e23dcca7",
   "metadata": {},
   "source": [
    "## Constructing the preprocessing stage\n",
    "The next step involves setting up the preprocessing stages. For the purpose of the demonstration, we will assume that this consists of a simple copy operation for each of the training, test and inference data. In a real-world scenario, this can be replaced by any other operation as required.\n",
    "\n",
    "In particular, a preprocessing stage may also involve manual user interaction (e.g. in a GUI) that cannot be reproduced from the command line and, hence, is executed outside of DVC. We will cover this case for the training data, whereas we use DVC-reproducible commands for the preprocessing of the other datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52279632-7466-4cf5-98e0-846fded33586",
   "metadata": {},
   "source": [
    "### Manual preprocessing\n",
    "To implement a manual preprocessing step for the `training` data, we create a DVC stage with a no-op command that is `frozen` in order not to be reproduced by `dvc repro` as configured in the app policy `dvc_app.yaml`. Nevertheless, the data dependencies of this stage are tracked in DVC via an ETL stage policy `dvc_etl.yaml`.\n",
    "\n",
    "To create this stage, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feea71be-a51e-4539-b91b-9ee85a4e7dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added stage 'app_prep_v1_manual_train_ex1-20230713-083624' in 'dvc.yaml'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add dvc.yaml .gitignore\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "Modifying stage 'app_prep_v1_manual_train_ex1-20230713-083624' in 'dvc.yaml'\n",
      "Not using SLURM or MPI in this DVC stage.\n",
      "Writing DVC stage to in/ml_dataset_v1/training/app_prep_v1/manual/ex1-20230713-083624\n",
      "Freezing stage for execution outside dvc - run 'dvc commit app_prep_v1_manual_train_ex1-20230713-083624' when outputs are done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "dvc_create_stage --app-yaml ../../app_prep/dvc_app.yaml --stage manual_train \\\n",
    "    --run-label ${ETL_TRAIN_RUN_LABEL} --input-etl ex1 --input-etl-file in.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32464eca-ecbc-46fe-9d31-df02a2ef0a32",
   "metadata": {},
   "source": [
    "To obtain the output data, the manual operation can now be performed. For this purpose, we inspect the newly created `dvc.yaml`. To perform a copy operation, we move the data in `deps` to the `output` directory in `outs`. As described above, in a real application, this step would typically be performed in a GUI app with some user interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd746b3b-b193-4d07-b501-82a90299e43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stages:\n",
      "  app_prep_v1_manual_train_ex1-20230713-083624:\n",
      "    desc: Generated with venv/bin/dvc_create_stage --app-yaml ../../app_prep/dvc_app.yaml\n",
      "      --stage manual_train --run-label ex1-20230713-083624 --input-etl ex1 --input-etl-file\n",
      "      in.dat at commit 9b25c0cefc87b7b60a2b956f5d64ed9a98f66372\n",
      "    cmd: if (set -o pipefail) 2>/dev/null; then set -o pipefail; fi; mkdir -p output\n",
      "      && bash -c \"true --etl-input ../../../original/ex1/in.dat --etl-output output\"\n",
      "      2>&1 | tee output/stage_out.log\n",
      "    deps:\n",
      "    - ../../../original/ex1\n",
      "    outs:\n",
      "    - output\n",
      "    frozen: true\n",
      "/home/lukasd/src/mitraccel/async-encfs-dvc/examples/data/v0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd in/ml_dataset_v1/training/app_prep_v1/manual/${ETL_TRAIN_RUN_LABEL}\n",
    "cat dvc.yaml\n",
    "cp ../../../original/ex1/* output/\n",
    "cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55710f11-05dd-432c-a1f2-170304450a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34min/ml_dataset_v1/training/app_prep_v1/manual/ex1-20230713-083624\u001b[00m\n",
      "├── dvc_app.yaml\n",
      "├── dvc.yaml\n",
      "└── \u001b[01;34moutput\u001b[00m\n",
      "    └── in.dat\n",
      "\n",
      "1 directory, 3 files\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tree in/ml_dataset_v1/training/app_prep_v1/manual/${ETL_TRAIN_RUN_LABEL}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07120c1-3a00-404a-8117-d879cef766b5",
   "metadata": {},
   "source": [
    "Once the manual operation has completed and the output directory is populated with data, we can commit it with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "033206e4-d8f0-4c01-aaec-9bb754ee0f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating lock file 'in/ml_dataset_v1/training/app_prep_v1/manual/ex1-20230713-083624/dvc.lock'\n",
      "Updating lock file 'in/ml_dataset_v1/training/app_prep_v1/manual/ex1-20230713-083624/dvc.lock'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "dvc commit --force in/ml_dataset_v1/training/app_prep_v1/manual/${ETL_TRAIN_RUN_LABEL}/dvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4bdda6-cc0c-4ae2-965f-57912d1d3a02",
   "metadata": {},
   "source": [
    "### Automated preprocessing\n",
    "In contrast, for the test and inference datasets, we will assume that the preprocessing is fully automated. These stages can be created and executed with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7738a05a-dba6-43ec-89ce-51275263d23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added stage 'app_prep_v1_auto_test_ex1-20230713-083951' in 'dvc.yaml'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add .gitignore dvc.yaml\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "Not using SLURM or MPI in this DVC stage.\n",
      "Writing DVC stage to in/ml_dataset_v1/test/app_prep_v1/auto/ex1-20230713-083951\n",
      "'in/ml_dataset_v1/test/original/ex1.dvc' didn't change, skipping\n",
      "Running stage 'in/ml_dataset_v1/test/app_prep_v1/auto/ex1-20230713-083951/dvc.yaml:app_prep_v1_auto_test_ex1-20230713-083951':\n",
      "> if (set -o pipefail) 2>/dev/null; then set -o pipefail; fi; mkdir -p output && bash -c \"$(git rev-parse --show-toplevel)/examples/app_prep/prep.sh --etl-input ../../../original/ex1/in.dat --etl-output output\" 2>&1 | tee output/stage_out.log\n",
      "+ cp ../../../original/ex1/in.dat output\n",
      "Generating lock file 'in/ml_dataset_v1/test/app_prep_v1/auto/ex1-20230713-083951/dvc.lock'\n",
      "Updating lock file 'in/ml_dataset_v1/test/app_prep_v1/auto/ex1-20230713-083951/dvc.lock'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add in/ml_dataset_v1/test/app_prep_v1/auto/ex1-20230713-083951/dvc.lock\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "Use `dvc push` to send your updates to remote storage.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# test-data\n",
    "dvc_create_stage --app-yaml ../../app_prep/dvc_app.yaml --stage auto_test \\\n",
    "    --run-label ${ETL_TEST_RUN_LABEL} --input-etl ex1 --input-etl-file in.dat\n",
    "dvc repro in/ml_dataset_v1/test/app_prep_v1/auto/${ETL_TEST_RUN_LABEL}/dvc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c76eca4-4dd0-4b68-aeda-ed390736f72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added stage 'app_prep_v1_auto_inf_ex1-20230713-083812' in 'dvc.yaml'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add .gitignore dvc.yaml\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "Not using SLURM or MPI in this DVC stage.\n",
      "Writing DVC stage to in/ml_dataset_v1/inference/app_prep_v1/auto/ex1-20230713-083812\n",
      "'in/ml_dataset_v1/inference/original/ex1.dvc' didn't change, skipping\n",
      "Stage 'in/ml_dataset_v1/inference/app_prep_v1/auto/ex1-20230713-083812/dvc.yaml:app_prep_v1_auto_inf_ex1-20230713-083812' is cached - skipping run, checking out outputs\n",
      "Generating lock file 'in/ml_dataset_v1/inference/app_prep_v1/auto/ex1-20230713-083812/dvc.lock'\n",
      "Updating lock file 'in/ml_dataset_v1/inference/app_prep_v1/auto/ex1-20230713-083812/dvc.lock'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add in/ml_dataset_v1/inference/app_prep_v1/auto/ex1-20230713-083812/dvc.lock\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "Use `dvc push` to send your updates to remote storage.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# inference-data\n",
    "dvc_create_stage --app-yaml ../../app_prep/dvc_app.yaml --stage auto_inf \\\n",
    "    --run-label ${ETL_INF_RUN_LABEL} --input-etl ex1 --input-etl-file in.dat\n",
    "dvc repro in/ml_dataset_v1/inference/app_prep_v1/auto/${ETL_INF_RUN_LABEL}/dvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d2b7db-30e3-4e11-8f86-7e83c234a56b",
   "metadata": {},
   "source": [
    "Execution can also be deferred to the ML stages, where it will be triggered as a dependency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae24d37d-9dd0-4d70-8bc9-6517043afef6",
   "metadata": {},
   "source": [
    "## Creating the Machine Learning stage\n",
    "Lastly, we will establish a rudimentary structure for a machine learning application that utilizes the preprocessed data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "262b4837-26cc-42f2-b380-93622d07a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p app_ml/ml_dataset_v1/model_name_v2/{training,inference,config}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22280d7e-cae3-4df3-8674-2201925fceeb",
   "metadata": {},
   "source": [
    "We encapsulate hyperparameters and model architecture specifications that are fixed during training in a file `hp.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cedc3fa-3321-4a09-8f79-f44f55f6ef51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25l⠋ Checking graph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add ex1-config.dvc .gitignore\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "/home/lukasd/src/mitraccel/async-encfs-dvc/examples/data/v0\n",
      "\u001b[01;34mapp_ml\u001b[00m\n",
      "└── \u001b[01;34mml_dataset_v1\u001b[00m\n",
      "    └── \u001b[01;34mmodel_name_v2\u001b[00m\n",
      "        ├── \u001b[01;34mconfig\u001b[00m\n",
      "        │   ├── \u001b[01;34mex1-config\u001b[00m\n",
      "        │   │   └── \u001b[01;34moutput\u001b[00m\n",
      "        │   │       └── hp.yaml\n",
      "        │   └── ex1-config.dvc\n",
      "        ├── \u001b[01;34minference\u001b[00m\n",
      "        └── \u001b[01;34mtraining\u001b[00m\n",
      "\n",
      "7 directories, 2 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25h\r"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir -p app_ml/ml_dataset_v1/model_name_v2/config/ex1-config/output\n",
    "touch app_ml/ml_dataset_v1/model_name_v2/config/ex1-config/output/hp.yaml\n",
    "cd app_ml/ml_dataset_v1/model_name_v2/config && dvc add ex1-config && cd -\n",
    "tree app_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92da4a45-331a-4a9c-8efa-33758d294102",
   "metadata": {},
   "source": [
    "Following this, we can set up the machine learning training and inference stages. Where necessary, we can obtain completion suggestions with `--show-opts`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c23763a0-4602-4932-895e-0967304ecb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added stage 'app_ml_ml_dataset_v1_model_name_v2_training_ex1-20230713-090119' in 'dvc.yaml'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add dvc.yaml .gitignore\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "Warning: stage argument --input-training-file not set (using Jinja2 default in app YAML if not --strict-mode).\n",
      "Warning: stage argument --input-test-file not set (using Jinja2 default in app YAML if not --strict-mode).\n",
      "Writing DVC stage to app_ml/ml_dataset_v1/model_name_v2/training/ex1-20230713-090119\n",
      "Added stage 'app_ml_ml_dataset_v1_model_name_v2_inference_ex1-20230713-121007' in 'dvc.yaml'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add dvc.yaml .gitignore\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "Warning: stage argument --input-training-file not set (using Jinja2 default in app YAML if not --strict-mode).\n",
      "Warning: stage argument --input-inference-file not set (using Jinja2 default in app YAML if not --strict-mode).\n",
      "Writing DVC stage to app_ml/ml_dataset_v1/model_name_v2/inference/ex1-20230713-121007\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "dvc_create_stage --app-yaml ../../app_ml/dvc_app.yaml --stage training \\\n",
    "    --run-label ${ML_TRAIN_RUN_LABEL} \\\n",
    "    --input-config ex1-config --input-config-file hp.yaml --input-training ${ETL_TRAIN_RUN_LABEL} --input-test ${ETL_TEST_RUN_LABEL}\n",
    "dvc_create_stage --app-yaml ../../app_ml/dvc_app.yaml --stage inference \\\n",
    "    --run-label ${ML_INF_RUN_LABEL} \\\n",
    "    --input-config ex1-config --input-config-file hp.yaml --input-training ${ML_TRAIN_RUN_LABEL} --input-inference ${ETL_INF_RUN_LABEL}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b50a3d-a9e5-43a9-aff9-dcd44fa351a4",
   "metadata": {},
   "source": [
    "## Running the pipeline\n",
    "These stages can be inspected with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1141181e-6424-4c28-86c0-6c729fa25dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strict digraph  {\n",
      "\"app_ml/ml_dataset_v1/model_name_v2/config/ex1-config.dvc\";\n",
      "\"app_ml/ml_dataset_v1/model_name_v2/training/ex1-20230713-090119/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_training_ex1-20230713-090119\";\n",
      "\"app_ml/ml_dataset_v1/model_name_v2/inference/ex1-20230713-121007/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_inference_ex1-20230713-121007\";\n",
      "\"in/ml_dataset_v1/training/app_prep_v1/manual/ex1-20230713-083624/dvc.yaml:app_prep_v1_manual_train_ex1-20230713-083624\";\n",
      "\"in/ml_dataset_v1/training/original/ex1.dvc\";\n",
      "\"in/ml_dataset_v1/inference/app_prep_v1/auto/ex1-20230713-083812/dvc.yaml:app_prep_v1_auto_inf_ex1-20230713-083812\";\n",
      "\"in/ml_dataset_v1/inference/original/ex1.dvc\";\n",
      "\"in/ml_dataset_v1/test/app_prep_v1/auto/ex1-20230713-083951/dvc.yaml:app_prep_v1_auto_test_ex1-20230713-083951\";\n",
      "\"in/ml_dataset_v1/test/original/ex1.dvc\";\n",
      "\"app_ml/ml_dataset_v1/model_name_v2/config/ex1-config.dvc\" -> \"app_ml/ml_dataset_v1/model_name_v2/training/ex1-20230713-090119/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_training_ex1-20230713-090119\";\n",
      "\"app_ml/ml_dataset_v1/model_name_v2/config/ex1-config.dvc\" -> \"app_ml/ml_dataset_v1/model_name_v2/inference/ex1-20230713-121007/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_inference_ex1-20230713-121007\";\n",
      "\"app_ml/ml_dataset_v1/model_name_v2/training/ex1-20230713-090119/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_training_ex1-20230713-090119\" -> \"app_ml/ml_dataset_v1/model_name_v2/inference/ex1-20230713-121007/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_inference_ex1-20230713-121007\";\n",
      "\"in/ml_dataset_v1/training/app_prep_v1/manual/ex1-20230713-083624/dvc.yaml:app_prep_v1_manual_train_ex1-20230713-083624\" -> \"app_ml/ml_dataset_v1/model_name_v2/training/ex1-20230713-090119/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_training_ex1-20230713-090119\";\n",
      "\"in/ml_dataset_v1/training/original/ex1.dvc\" -> \"in/ml_dataset_v1/training/app_prep_v1/manual/ex1-20230713-083624/dvc.yaml:app_prep_v1_manual_train_ex1-20230713-083624\";\n",
      "\"in/ml_dataset_v1/inference/app_prep_v1/auto/ex1-20230713-083812/dvc.yaml:app_prep_v1_auto_inf_ex1-20230713-083812\" -> \"app_ml/ml_dataset_v1/model_name_v2/inference/ex1-20230713-121007/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_inference_ex1-20230713-121007\";\n",
      "\"in/ml_dataset_v1/inference/original/ex1.dvc\" -> \"in/ml_dataset_v1/inference/app_prep_v1/auto/ex1-20230713-083812/dvc.yaml:app_prep_v1_auto_inf_ex1-20230713-083812\";\n",
      "\"in/ml_dataset_v1/test/app_prep_v1/auto/ex1-20230713-083951/dvc.yaml:app_prep_v1_auto_test_ex1-20230713-083951\" -> \"app_ml/ml_dataset_v1/model_name_v2/training/ex1-20230713-090119/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_training_ex1-20230713-090119\";\n",
      "\"in/ml_dataset_v1/test/original/ex1.dvc\" -> \"in/ml_dataset_v1/test/app_prep_v1/auto/ex1-20230713-083951/dvc.yaml:app_prep_v1_auto_test_ex1-20230713-083951\";\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "dvc dag --dot app_ml/ml_dataset_v1/model_name_v2/inference/${ML_INF_RUN_LABEL}/dvc.yaml | tee app_ml/ml_dataset_v1/model_name_v2/inference/${ML_INF_RUN_LABEL}/dvc_dag.dot\n",
    "if [[ $(command -v dot) ]]; then\n",
    "    dot -Tsvg app_ml/ml_dataset_v1/model_name_v2/inference/${ML_INF_RUN_LABEL}/dvc_dag.dot > app_ml/ml_dataset_v1/model_name_v2/inference/${ML_INF_RUN_LABEL}/dvc_dag.svg\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "587cc186-b78b-4df0-a900-713b4e4168b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"3456pt\" height=\"260pt\" viewBox=\"0.00 0.00 3455.87 260.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-256 3451.87,-256 3451.87,4 -4,4\"/>\n",
       "<!-- app_ml/ml_dataset_v1/model_name_v2/config/ex1&#45;config.dvc -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>app_ml/ml_dataset_v1/model_name_v2/config/ex1-config.dvc</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"289.87\" cy=\"-162\" rx=\"289.75\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"289.87\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">app_ml/ml_dataset_v1/model_name_v2/config/ex1-config.dvc</text>\n",
       "</g>\n",
       "<!-- app_ml/ml_dataset_v1/model_name_v2/training/ex1&#45;20230713&#45;090119/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_training_ex1&#45;20230713&#45;090119 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>app_ml/ml_dataset_v1/model_name_v2/training/ex1-20230713-090119/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_training_ex1-20230713-090119</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1211.87\" cy=\"-90\" rx=\"716.47\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1211.87\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">app_ml/ml_dataset_v1/model_name_v2/training/ex1-20230713-090119/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_training_ex1-20230713-090119</text>\n",
       "</g>\n",
       "<!-- app_ml/ml_dataset_v1/model_name_v2/config/ex1&#45;config.dvc&#45;&gt;app_ml/ml_dataset_v1/model_name_v2/training/ex1&#45;20230713&#45;090119/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_training_ex1&#45;20230713&#45;090119 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>app_ml/ml_dataset_v1/model_name_v2/config/ex1-config.dvc-&gt;app_ml/ml_dataset_v1/model_name_v2/training/ex1-20230713-090119/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_training_ex1-20230713-090119</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M465.47,-147.67C614.01,-136.39 827.72,-120.17 988.43,-107.96\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"988.75,-111.45 998.46,-107.2 988.22,-104.47 988.75,-111.45\"/>\n",
       "</g>\n",
       "<!-- app_ml/ml_dataset_v1/model_name_v2/inference/ex1&#45;20230713&#45;121007/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_inference_ex1&#45;20230713&#45;121007 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>app_ml/ml_dataset_v1/model_name_v2/inference/ex1-20230713-121007/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_inference_ex1-20230713-121007</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1211.87\" cy=\"-18\" rx=\"728.67\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1211.87\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">app_ml/ml_dataset_v1/model_name_v2/inference/ex1-20230713-121007/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_inference_ex1-20230713-121007</text>\n",
       "</g>\n",
       "<!-- app_ml/ml_dataset_v1/model_name_v2/config/ex1&#45;config.dvc&#45;&gt;app_ml/ml_dataset_v1/model_name_v2/inference/ex1&#45;20230713&#45;121007/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_inference_ex1&#45;20230713&#45;121007 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>app_ml/ml_dataset_v1/model_name_v2/config/ex1-config.dvc-&gt;app_ml/ml_dataset_v1/model_name_v2/inference/ex1-20230713-121007/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_inference_ex1-20230713-121007</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M318.73,-144.04C356.1,-123.01 423.94,-87.98 486.87,-72 554.52,-54.83 699.02,-42.6 841.36,-34.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"841.82,-37.73 851.6,-33.66 841.42,-30.74 841.82,-37.73\"/>\n",
       "</g>\n",
       "<!-- app_ml/ml_dataset_v1/model_name_v2/training/ex1&#45;20230713&#45;090119/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_training_ex1&#45;20230713&#45;090119&#45;&gt;app_ml/ml_dataset_v1/model_name_v2/inference/ex1&#45;20230713&#45;121007/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_inference_ex1&#45;20230713&#45;121007 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>app_ml/ml_dataset_v1/model_name_v2/training/ex1-20230713-090119/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_training_ex1-20230713-090119-&gt;app_ml/ml_dataset_v1/model_name_v2/inference/ex1-20230713-121007/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_inference_ex1-20230713-121007</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1211.87,-71.7C1211.87,-63.98 1211.87,-54.71 1211.87,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1215.37,-46.1 1211.87,-36.1 1208.37,-46.1 1215.37,-46.1\"/>\n",
       "</g>\n",
       "<!-- in/ml_dataset_v1/training/app_prep_v1/manual/ex1&#45;20230713&#45;083624/dvc.yaml:app_prep_v1_manual_train_ex1&#45;20230713&#45;083624 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>in/ml_dataset_v1/training/app_prep_v1/manual/ex1-20230713-083624/dvc.yaml:app_prep_v1_manual_train_ex1-20230713-083624</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1211.87\" cy=\"-162\" rx=\"614.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1211.87\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">in/ml_dataset_v1/training/app_prep_v1/manual/ex1-20230713-083624/dvc.yaml:app_prep_v1_manual_train_ex1-20230713-083624</text>\n",
       "</g>\n",
       "<!-- in/ml_dataset_v1/training/app_prep_v1/manual/ex1&#45;20230713&#45;083624/dvc.yaml:app_prep_v1_manual_train_ex1&#45;20230713&#45;083624&#45;&gt;app_ml/ml_dataset_v1/model_name_v2/training/ex1&#45;20230713&#45;090119/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_training_ex1&#45;20230713&#45;090119 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>in/ml_dataset_v1/training/app_prep_v1/manual/ex1-20230713-083624/dvc.yaml:app_prep_v1_manual_train_ex1-20230713-083624-&gt;app_ml/ml_dataset_v1/model_name_v2/training/ex1-20230713-090119/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_training_ex1-20230713-090119</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1211.87,-143.7C1211.87,-135.98 1211.87,-126.71 1211.87,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1215.37,-118.1 1211.87,-108.1 1208.37,-118.1 1215.37,-118.1\"/>\n",
       "</g>\n",
       "<!-- in/ml_dataset_v1/training/original/ex1.dvc -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>in/ml_dataset_v1/training/original/ex1.dvc</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1211.87\" cy=\"-234\" rx=\"206.06\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1211.87\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">in/ml_dataset_v1/training/original/ex1.dvc</text>\n",
       "</g>\n",
       "<!-- in/ml_dataset_v1/training/original/ex1.dvc&#45;&gt;in/ml_dataset_v1/training/app_prep_v1/manual/ex1&#45;20230713&#45;083624/dvc.yaml:app_prep_v1_manual_train_ex1&#45;20230713&#45;083624 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>in/ml_dataset_v1/training/original/ex1.dvc-&gt;in/ml_dataset_v1/training/app_prep_v1/manual/ex1-20230713-083624/dvc.yaml:app_prep_v1_manual_train_ex1-20230713-083624</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1211.87,-215.7C1211.87,-207.98 1211.87,-198.71 1211.87,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1215.37,-190.1 1211.87,-180.1 1208.37,-190.1 1215.37,-190.1\"/>\n",
       "</g>\n",
       "<!-- in/ml_dataset_v1/inference/app_prep_v1/auto/ex1&#45;20230713&#45;083812/dvc.yaml:app_prep_v1_auto_inf_ex1&#45;20230713&#45;083812 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>in/ml_dataset_v1/inference/app_prep_v1/auto/ex1-20230713-083812/dvc.yaml:app_prep_v1_auto_inf_ex1-20230713-083812</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2864.87\" cy=\"-90\" rx=\"583\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2864.87\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">in/ml_dataset_v1/inference/app_prep_v1/auto/ex1-20230713-083812/dvc.yaml:app_prep_v1_auto_inf_ex1-20230713-083812</text>\n",
       "</g>\n",
       "<!-- in/ml_dataset_v1/inference/app_prep_v1/auto/ex1&#45;20230713&#45;083812/dvc.yaml:app_prep_v1_auto_inf_ex1&#45;20230713&#45;083812&#45;&gt;app_ml/ml_dataset_v1/model_name_v2/inference/ex1&#45;20230713&#45;121007/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_inference_ex1&#45;20230713&#45;121007 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>in/ml_dataset_v1/inference/app_prep_v1/auto/ex1-20230713-083812/dvc.yaml:app_prep_v1_auto_inf_ex1-20230713-083812-&gt;app_ml/ml_dataset_v1/model_name_v2/inference/ex1-20230713-121007/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_inference_ex1-20230713-121007</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2536.81,-75.11C2258.18,-63.31 1858.9,-46.4 1571.59,-34.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1571.56,-30.73 1561.42,-33.8 1571.26,-37.72 1571.56,-30.73\"/>\n",
       "</g>\n",
       "<!-- in/ml_dataset_v1/inference/original/ex1.dvc -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>in/ml_dataset_v1/inference/original/ex1.dvc</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3200.87\" cy=\"-162\" rx=\"211.76\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"3200.87\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">in/ml_dataset_v1/inference/original/ex1.dvc</text>\n",
       "</g>\n",
       "<!-- in/ml_dataset_v1/inference/original/ex1.dvc&#45;&gt;in/ml_dataset_v1/inference/app_prep_v1/auto/ex1&#45;20230713&#45;083812/dvc.yaml:app_prep_v1_auto_inf_ex1&#45;20230713&#45;083812 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>in/ml_dataset_v1/inference/original/ex1.dvc-&gt;in/ml_dataset_v1/inference/app_prep_v1/auto/ex1-20230713-083812/dvc.yaml:app_prep_v1_auto_inf_ex1-20230713-083812</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3124.63,-145.12C3074.52,-134.68 3008.69,-120.96 2955.85,-109.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2956.3,-106.47 2945.8,-107.86 2954.87,-113.33 2956.3,-106.47\"/>\n",
       "</g>\n",
       "<!-- in/ml_dataset_v1/test/app_prep_v1/auto/ex1&#45;20230713&#45;083951/dvc.yaml:app_prep_v1_auto_test_ex1&#45;20230713&#45;083951 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>in/ml_dataset_v1/test/app_prep_v1/auto/ex1-20230713-083951/dvc.yaml:app_prep_v1_auto_test_ex1-20230713-083951</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2407.87\" cy=\"-162\" rx=\"563.5\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2407.87\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">in/ml_dataset_v1/test/app_prep_v1/auto/ex1-20230713-083951/dvc.yaml:app_prep_v1_auto_test_ex1-20230713-083951</text>\n",
       "</g>\n",
       "<!-- in/ml_dataset_v1/test/app_prep_v1/auto/ex1&#45;20230713&#45;083951/dvc.yaml:app_prep_v1_auto_test_ex1&#45;20230713&#45;083951&#45;&gt;app_ml/ml_dataset_v1/model_name_v2/training/ex1&#45;20230713&#45;090119/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_training_ex1&#45;20230713&#45;090119 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>in/ml_dataset_v1/test/app_prep_v1/auto/ex1-20230713-083951/dvc.yaml:app_prep_v1_auto_test_ex1-20230713-083951-&gt;app_ml/ml_dataset_v1/model_name_v2/training/ex1-20230713-090119/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_training_ex1-20230713-090119</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2150.94,-145.96C1956.43,-134.58 1689.62,-118.96 1490.09,-107.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1490.23,-103.79 1480.04,-106.7 1489.82,-110.77 1490.23,-103.79\"/>\n",
       "</g>\n",
       "<!-- in/ml_dataset_v1/test/original/ex1.dvc -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>in/ml_dataset_v1/test/original/ex1.dvc</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2407.87\" cy=\"-234\" rx=\"186.57\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2407.87\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">in/ml_dataset_v1/test/original/ex1.dvc</text>\n",
       "</g>\n",
       "<!-- in/ml_dataset_v1/test/original/ex1.dvc&#45;&gt;in/ml_dataset_v1/test/app_prep_v1/auto/ex1&#45;20230713&#45;083951/dvc.yaml:app_prep_v1_auto_test_ex1&#45;20230713&#45;083951 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>in/ml_dataset_v1/test/original/ex1.dvc-&gt;in/ml_dataset_v1/test/app_prep_v1/auto/ex1-20230713-083951/dvc.yaml:app_prep_v1_auto_test_ex1-20230713-083951</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2407.87,-215.7C2407.87,-207.98 2407.87,-198.71 2407.87,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2411.37,-190.1 2407.87,-180.1 2404.37,-190.1 2411.37,-190.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dvc_dag_img = 'app_ml/ml_dataset_v1/model_name_v2/inference/' + os.environ['ML_INF_RUN_LABEL'] + '/dvc_dag.svg'  # test_ml_tutorial: skip\n",
    "if os.path.exists(dvc_dag_img):  # test_ml_tutorial: skip\n",
    "    display(SVG(filename=dvc_dag_img))  # test_ml_tutorial: skip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5093f914-a50b-4ee0-b94e-579cf8ec5c82",
   "metadata": {},
   "source": [
    "And finally executed with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dec8894-90c8-432a-876c-443a77333032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'app_ml/ml_dataset_v1/model_name_v2/config/ex1-config.dvc' didn't change, skipping\n",
      "'in/ml_dataset_v1/test/original/ex1.dvc' didn't change, skipping\n",
      "Stage 'in/ml_dataset_v1/test/app_prep_v1/auto/ex1-20230713-083951/dvc.yaml:app_prep_v1_auto_test_ex1-20230713-083951' didn't change, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: stage: 'in/ml_dataset_v1/training/app_prep_v1/manual/ex1-20230713-083624/dvc.yaml:app_prep_v1_manual_train_ex1-20230713-083624' is frozen. Its dependencies are not going to be reproduced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 'in/ml_dataset_v1/training/app_prep_v1/manual/ex1-20230713-083624/dvc.yaml:app_prep_v1_manual_train_ex1-20230713-083624' didn't change, skipping\n",
      "Running stage 'app_ml/ml_dataset_v1/model_name_v2/training/ex1-20230713-090119/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_training_ex1-20230713-090119':\n",
      "> if (set -o pipefail) 2>/dev/null; then set -o pipefail; fi; mkdir -p output && bash -c \"time mpiexec -np 2 $(git rev-parse --show-toplevel)/examples/app_ml/training.sh --training-input ../../../../../in/ml_dataset_v1/training/app_prep_v1/manual/ex1-20230713-083624/output --test-input ../../../../../in/ml_dataset_v1/test/app_prep_v1/auto/ex1-20230713-083951/output --config ../../config/ex1-config/output/hp.yaml --training-output output\" 2>&1 | tee output/stage_out.log\n",
      "training.sh: cd /src/app\n",
      "training.sh: source venv/bin/activate\n",
      "training.sh: cd /src/app\n",
      "training.sh: source venv/bin/activate\n",
      "++ dirname /home/lukasd/src/mitraccel/async-encfs-dvc/examples/app_ml/training.sh\n",
      "++ dirname /home/lukasd/src/mitraccel/async-encfs-dvc/examples/app_ml/training.sh\n",
      "+ exec python3 -u /home/lukasd/src/mitraccel/async-encfs-dvc/examples/app_ml/training.py --training-input ../../../../../in/ml_dataset_v1/training/app_prep_v1/manual/ex1-20230713-083624/output --test-input ../../../../../in/ml_dataset_v1/test/app_prep_v1/auto/ex1-20230713-083951/output --config ../../config/ex1-config/output/hp.yaml --training-output output\n",
      "+ exec python3 -u /home/lukasd/src/mitraccel/async-encfs-dvc/examples/app_ml/training.py --training-input ../../../../../in/ml_dataset_v1/training/app_prep_v1/manual/ex1-20230713-083624/output --test-input ../../../../../in/ml_dataset_v1/test/app_prep_v1/auto/ex1-20230713-083951/output --config ../../config/ex1-config/output/hp.yaml --training-output output\n",
      "Running training (/home/lukasd/src/mitraccel/async-encfs-dvc/examples/app_ml/training.py, output-dir output) with args\n",
      "['/home/lukasd/src/mitraccel/async-encfs-dvc/examples/app_ml/training.py', '--training-input', '../../../../../in/ml_dataset_v1/training/app_prep_v1/manual/ex1-20230713-083624/output', '--test-input', '../../../../../in/ml_dataset_v1/test/app_prep_v1/auto/ex1-20230713-083951/output', '--config', '../../config/ex1-config/output/hp.yaml', '--training-output', 'output']\n",
      "\n",
      "Running training (/home/lukasd/src/mitraccel/async-encfs-dvc/examples/app_ml/training.py, output-dir output) with args\n",
      "['/home/lukasd/src/mitraccel/async-encfs-dvc/examples/app_ml/training.py', '--training-input', '../../../../../in/ml_dataset_v1/training/app_prep_v1/manual/ex1-20230713-083624/output', '--test-input', '../../../../../in/ml_dataset_v1/test/app_prep_v1/auto/ex1-20230713-083951/output', '--config', '../../config/ex1-config/output/hp.yaml', '--training-output', 'output']\n",
      "\n",
      "\n",
      "real\t0m0.039s\n",
      "user\t0m0.064s\n",
      "sys\t0m0.011s\n",
      "Generating lock file 'app_ml/ml_dataset_v1/model_name_v2/training/ex1-20230713-090119/dvc.lock'\n",
      "Updating lock file 'app_ml/ml_dataset_v1/model_name_v2/training/ex1-20230713-090119/dvc.lock'\n",
      "\n",
      "'in/ml_dataset_v1/inference/original/ex1.dvc' didn't change, skipping\n",
      "Stage 'in/ml_dataset_v1/inference/app_prep_v1/auto/ex1-20230713-083812/dvc.yaml:app_prep_v1_auto_inf_ex1-20230713-083812' didn't change, skipping\n",
      "Running stage 'app_ml/ml_dataset_v1/model_name_v2/inference/ex1-20230713-121007/dvc.yaml:app_ml_ml_dataset_v1_model_name_v2_inference_ex1-20230713-121007':\n",
      "> if (set -o pipefail) 2>/dev/null; then set -o pipefail; fi; mkdir -p output && bash -c \"time mpiexec -np 1 $(git rev-parse --show-toplevel)/examples/app_ml/inference.sh --training-output ../../training/ex1-20230713-090119/output --inference-input ../../../../../in/ml_dataset_v1/inference/app_prep_v1/auto/ex1-20230713-083812/output --config ../../config/ex1-config/output/hp.yaml --inference-output output\" 2>&1 | tee output/stage_out.log\n",
      "inference.sh: cd /src/app\n",
      "inference.sh: source venv/bin/activate\n",
      "++ dirname /home/lukasd/src/mitraccel/async-encfs-dvc/examples/app_ml/inference.sh\n",
      "+ exec python3 -u /home/lukasd/src/mitraccel/async-encfs-dvc/examples/app_ml/inference.py --training-output ../../training/ex1-20230713-090119/output --inference-input ../../../../../in/ml_dataset_v1/inference/app_prep_v1/auto/ex1-20230713-083812/output --config ../../config/ex1-config/output/hp.yaml --inference-output output\n",
      "Running inference (/home/lukasd/src/mitraccel/async-encfs-dvc/examples/app_ml/inference.py, output-dir output) with args\n",
      "['/home/lukasd/src/mitraccel/async-encfs-dvc/examples/app_ml/inference.py', '--training-output', '../../training/ex1-20230713-090119/output', '--inference-input', '../../../../../in/ml_dataset_v1/inference/app_prep_v1/auto/ex1-20230713-083812/output', '--config', '../../config/ex1-config/output/hp.yaml', '--inference-output', 'output']\n",
      "\n",
      "\n",
      "real\t0m0.043s\n",
      "user\t0m0.039s\n",
      "sys\t0m0.004s\n",
      "Generating lock file 'app_ml/ml_dataset_v1/model_name_v2/inference/ex1-20230713-121007/dvc.lock'\n",
      "Updating lock file 'app_ml/ml_dataset_v1/model_name_v2/inference/ex1-20230713-121007/dvc.lock'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add app_ml/ml_dataset_v1/model_name_v2/training/ex1-20230713-090119/dvc.lock app_ml/ml_dataset_v1/model_name_v2/inference/ex1-20230713-121007/dvc.lock\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "Use `dvc push` to send your updates to remote storage.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "dvc repro app_ml/ml_dataset_v1/model_name_v2/inference/${ML_INF_RUN_LABEL}/dvc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d18e7364-2734-4b47-a0d9-19d080938585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34min\u001b[00m\n",
      "└── \u001b[01;34mml_dataset_v1\u001b[00m\n",
      "    ├── \u001b[01;34minference\u001b[00m\n",
      "    │   ├── \u001b[01;34mapp_prep_v1\u001b[00m\n",
      "    │   │   └── \u001b[01;34mauto\u001b[00m\n",
      "    │   │       └── \u001b[01;34mex1-20230713-083812\u001b[00m\n",
      "    │   │           ├── dvc_app.yaml\n",
      "    │   │           ├── dvc.lock\n",
      "    │   │           ├── dvc.yaml\n",
      "    │   │           └── \u001b[01;34moutput\u001b[00m\n",
      "    │   │               ├── in.dat\n",
      "    │   │               └── stage_out.log\n",
      "    │   └── \u001b[01;34moriginal\u001b[00m\n",
      "    │       ├── \u001b[01;34mex1\u001b[00m\n",
      "    │       │   └── in.dat\n",
      "    │       └── ex1.dvc\n",
      "    ├── \u001b[01;34mtest\u001b[00m\n",
      "    │   ├── \u001b[01;34mapp_prep_v1\u001b[00m\n",
      "    │   │   └── \u001b[01;34mauto\u001b[00m\n",
      "    │   │       └── \u001b[01;34mex1-20230713-083951\u001b[00m\n",
      "    │   │           ├── dvc_app.yaml\n",
      "    │   │           ├── dvc.lock\n",
      "    │   │           ├── dvc.yaml\n",
      "    │   │           └── \u001b[01;34moutput\u001b[00m\n",
      "    │   │               ├── in.dat\n",
      "    │   │               └── stage_out.log\n",
      "    │   └── \u001b[01;34moriginal\u001b[00m\n",
      "    │       ├── \u001b[01;34mex1\u001b[00m\n",
      "    │       │   └── in.dat\n",
      "    │       └── ex1.dvc\n",
      "    └── \u001b[01;34mtraining\u001b[00m\n",
      "        ├── \u001b[01;34mapp_prep_v1\u001b[00m\n",
      "        │   └── \u001b[01;34mmanual\u001b[00m\n",
      "        │       └── \u001b[01;34mex1-20230713-083624\u001b[00m\n",
      "        │           ├── dvc_app.yaml\n",
      "        │           ├── dvc.lock\n",
      "        │           ├── dvc.yaml\n",
      "        │           └── \u001b[01;34moutput\u001b[00m\n",
      "        │               └── in.dat\n",
      "        └── \u001b[01;34moriginal\u001b[00m\n",
      "            ├── \u001b[01;34mex1\u001b[00m\n",
      "            │   └── in.dat\n",
      "            └── ex1.dvc\n",
      "\u001b[01;34mapp_ml\u001b[00m\n",
      "└── \u001b[01;34mml_dataset_v1\u001b[00m\n",
      "    └── \u001b[01;34mmodel_name_v2\u001b[00m\n",
      "        ├── \u001b[01;34mconfig\u001b[00m\n",
      "        │   ├── \u001b[01;34mex1-config\u001b[00m\n",
      "        │   │   └── \u001b[01;34moutput\u001b[00m\n",
      "        │   │       └── hp.yaml\n",
      "        │   └── ex1-config.dvc\n",
      "        ├── \u001b[01;34minference\u001b[00m\n",
      "        │   └── \u001b[01;34mex1-20230713-121007\u001b[00m\n",
      "        │       ├── dvc_app.yaml\n",
      "        │       ├── dvc_dag.dot\n",
      "        │       ├── \u001b[01;35mdvc_dag.svg\u001b[00m\n",
      "        │       ├── dvc.lock\n",
      "        │       ├── dvc.yaml\n",
      "        │       └── \u001b[01;34moutput\u001b[00m\n",
      "        │           └── stage_out.log\n",
      "        └── \u001b[01;34mtraining\u001b[00m\n",
      "            └── \u001b[01;34mex1-20230713-090119\u001b[00m\n",
      "                ├── dvc_app.yaml\n",
      "                ├── dvc.lock\n",
      "                ├── dvc.yaml\n",
      "                └── \u001b[01;34moutput\u001b[00m\n",
      "                    └── stage_out.log\n",
      "\n",
      "33 directories, 32 files\n"
     ]
    }
   ],
   "source": [
    "!tree in app_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056535e7-bb2b-41ec-aff8-b9c647f5c568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
