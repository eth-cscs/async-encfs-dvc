{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e1e3f1f-753d-462b-88bd-b31d918896c1",
   "metadata": {},
   "source": [
    "# A PyTorch Vision Transformer example with EncFS and SLURM\n",
    "\n",
    "This application shows the concepts previously introduced in tutorials - DVC policies, EncFS and SLURM - in action with a [Vision Transformer](https://github.com/pytorch/examples/blob/main/vision_transformer) network from the PyTorch example collection that is applied to the CIFAR10 dataset. Even though we do not use containers here, an extension to use the Sarus container engine can be done without difficulty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f276f6c3-08cf-409b-b1e3-6e767e0e82db",
   "metadata": {},
   "source": [
    "## Initializing the DVC repository\n",
    "We first import the depencies for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af8552e-1d3e-4c31-b410-627b1de89fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac94128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG  # test_vit_example: skip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65be096-eb8e-4d18-a2e2-858ea136b47b",
   "metadata": {},
   "source": [
    "Create a new directory `data/v3` for the DVC root and change to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd315e-6ab4-4e75-8a85-4056b09563ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data/v3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5823a232-0796-405f-af6d-ecda49add286",
   "metadata": {},
   "source": [
    "Initialize an `encfs` DVC repository as explained in the [EncFS-simulation tutorial](encfs_sim_tutorial.ipynb) using the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878f12d8-3b44-40f4-8bd2-ffb2dd84fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc_init_repo . encfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c502c32-a686-4818-99ca-e3d1d040839e",
   "metadata": {},
   "source": [
    "As next step, EncFS needs to be configured, which can be achieved by running\n",
    "\n",
    "```shell\n",
    "${ENCFS_INSTALL_DIR}/bin/encfs -o allow_root,max_write=1048576,big_writes -f encrypt decrypt\n",
    "```\n",
    "as described in the [EncFS initialization instructions](../async_encfs_dvc/encfs_int/README.md).\n",
    "\n",
    "Here, only for the purpose of this tutorial, we use a pre-established configuration with a simple password. It is important that this is only for demonstration purposes - in practice always generate a **random** key and store it in a **safe location**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa7bed3-2011-4a48-a94b-1798f76edcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo 1234 > encfs_tutorial.key\n",
    "cp $(git rev-parse --show-toplevel)/examples/.encfs6.xml.tutorial encrypt/ && mv encrypt/.encfs6.xml.tutorial encrypt/.encfs6.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30981619-edde-406b-8a4a-74340a078b42",
   "metadata": {},
   "source": [
    "At runtime, EncFS will read the password from a file. The location of that file is passed in an environment variable that has to be set when `dvc repro` is run on a stage or `encfs_launch` is used to e.g. inspect the encrypted data interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc404dba-7668-4037-9b12-9d9755967e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ENCFS_PW_FILE'] = os.path.realpath('encfs_tutorial.key')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6e1e70-9135-4c7c-954f-af0c5b850341",
   "metadata": {},
   "source": [
    "The DVC repo has been initialized with repo and stage policies available under `.dvc_policies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d25ced6-1813-4891-895a-8963bb46a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree .dvc_policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aaefd1-e2d6-4322-a02c-7937db59870d",
   "metadata": {},
   "source": [
    "For the purpose of this tutorial, we will extract the paths of the encrypted directory and the mount target of EncFS into environment variables. This is not a necessary step to run DVC stages with EncFS, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1a40b-15b0-4e53-b16f-50ec24a4909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from async_encfs_dvc.encfs_int.mount_config import load_mount_config\n",
    "\n",
    "mount_config = [os.popen(f\"echo {d}\").read().strip() for d in  # evaluating shell exprs in paths\n",
    "                load_mount_config('.dvc_policies/repo/dvc_root.yaml')]\n",
    "\n",
    "os.environ['ENCFS_ENCRYPT_DIR'] = mount_config[0]  # encrypt (same on all hosts)\n",
    "os.environ['ENCFS_DECRYPT_DIR'] = mount_config[1]  # host-specific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c1eae6-bdeb-491c-a3dc-1d8ae82b6e6c",
   "metadata": {},
   "source": [
    "## Fetching the input dataset\n",
    "Our pipeline will be based on the CIFAR10 dataset. For the purpose of this example, we will use the test dataset also as an input at the inference stage. The CIFAR10 dataset requires training and test dataset to be co-located. Therefore, we will not use the same fine-grained DVC file hierarchy as in the ML tutorial, where for each of training, test and inference the original and preprocessed data was grouped. We download the dataset using the code in `ex_in` and track it with DVC using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689647a9-2b5a-4f59-b153-b10147ccec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CIFAR10_IN_RUN_LABEL=init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fa28d0-9aa6-4847-aa0d-53f40385ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc_create_stage --app-yaml ../../ex_in/dvc_app.yaml --stage fetch_cifar10 --run-label ${CIFAR10_IN_RUN_LABEL}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525a331d-ac6d-464a-805f-9ce38de6222e",
   "metadata": {},
   "source": [
    "This stage can be executed, frozen upon success and the resulting file hierarchy inspected with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102870a6-3156-4b36-b72e-b368dca773e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!dvc repro --no-commit config/in/cifar10/original/dvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a090117-4ed9-4e3c-abd2-6f8fc0790b4f",
   "metadata": {},
   "source": [
    "As an asynchronous SLURM stage, we have to wait for its completion until we can inspect the data. As shown in the [SLURM tutorial](slurm_async_sim_tutorial.ipynb), this includes first releasing the stage and commit jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc32ff-9a29-40d7-ad1f-8a36cfe654d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc_scontrol release stage,commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd99c7fe-b8a5-4461-bbc9-e8be32d2cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "!../../slurm_wait_for_job.sh $(cat config/in/cifar10/original/in_original_fetch_cifar10_${CIFAR10_IN_RUN_LABEL}.dvc_commit_jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc792f8-876f-44f8-8d4a-20318f9c18be",
   "metadata": {},
   "source": [
    "As we do not expect this dataset to change, we can freeze this input stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547f74da-016e-4572-940c-d541ed40fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc freeze config/in/cifar10/original/dvc.yaml:in_original_fetch_cifar10_${CIFAR10_IN_RUN_LABEL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175b2669-395f-472a-8bdc-ace04b4b29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree encrypt/in config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb09321-fa1c-4141-b265-736a9c391ef2",
   "metadata": {},
   "source": [
    "We convince ourselves that the data is encrypted as demonstrated in the [EncFS-simulation tutorial](encfs_sim_tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf58fa5-6bb2-472f-8d0f-3eb3bc793dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head encrypt/in/cifar10/original/output/cifar-10-batches-py/readme.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0223c531-0833-4f95-bf25-a1ca84b9279e",
   "metadata": {},
   "source": [
    "whereas it can readily be inspected with EncFS (*never* handle confidential data in this way, always use `encfs_launch` as advised in the EncFS-tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cbf6a1-3d65-459f-b766-6998139c8bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "encfs_mount_and_run encrypt ${ENCFS_DECRYPT_DIR} /dev/null cp ${ENCFS_DECRYPT_DIR}/in/cifar10/original/output/cifar-10-batches-py/readme.html readme.html >/dev/null\n",
    "head readme.html\n",
    "rm readme.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c3900-edd2-4cb0-8fb1-1fcba605624a",
   "metadata": {},
   "source": [
    "The execution of the data fetch stage can also be deferred to the ML stages, where it will be triggered as a dependency.\n",
    "\n",
    "Before moving to the next stage, we define execution labels based on timestamps for the subsequent DVC stages. In a real-world application, the timestamps would usually be generated on the fly when creating the DVC stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae5a9cc-eee6-4c68-b9fe-46e195a0619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env VIT_TRAIN_RUN_LABEL=run_20230721_081756\n",
    "%env VIT_INF_RUN_LABEL=run_20230721_115412"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b9e318-748a-4d20-a90b-f352e23dcca7",
   "metadata": {},
   "source": [
    "The next step usually involves setting up preprocessing stages. In the Vision Transformer example, this corresponds to resizing the images. Since this is an inexpensive operation and comes integrated with the training and inference in the publicly available code, we will skip this. For instructions on how to define a separate preprocessing step, please refer to the [ML repository tutorial](ml_tutorial.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae24d37d-9dd0-4d70-8bc9-6517043afef6",
   "metadata": {},
   "source": [
    "## Creating the training and inference stages\n",
    "Now, we are ready to set up the stages for the Vision Transformer model based on the CIFAR10 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262b4837-26cc-42f2-b380-93622d07a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p {encrypt,config}/ex_vit/cifar10/baseline_model/{training,inference,config}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22280d7e-cae3-4df3-8674-2201925fceeb",
   "metadata": {},
   "source": [
    "We capture the model configuration and output under the name `baseline_model` to refer to the publicly available model. The default values for hyperparameters and model architecture specification are encapsulated in a file `config.yaml`. We commit this file to the DVC repository using a `config` stage analogous to the manual input stage for datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb9a2f8-be4f-426f-9bbb-ab956ac03c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc_create_stage --app-yaml ../../ex_vit/dvc_app.yaml --stage config --run-label init --config-group default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cedc3fa-3321-4a09-8f79-f44f55f6ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "!encfs_mount_and_run encrypt ${ENCFS_DECRYPT_DIR} config/ex_vit/cifar10/baseline_model/config/default/output/stage_log.out cp -v ../../ex_vit/config.yaml ${ENCFS_DECRYPT_DIR}/ex_vit/cifar10/baseline_model/config/default/output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9467107-8816-4ccd-a480-2ae800a56c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc commit --force config/ex_vit/cifar10/baseline_model/config/default/dvc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f177211-b430-468e-aa08-aca63277e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree {encrypt,config}/ex_vit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92da4a45-331a-4a9c-8efa-33758d294102",
   "metadata": {},
   "source": [
    "Following this, we can set up the training and inference stages. Where necessary, we can obtain completion suggestions with `--show-opts`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23763a0-4602-4932-895e-0967304ecb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "dvc_create_stage --app-yaml ../../ex_vit/dvc_app.yaml --stage training \\\n",
    "    --run-label ${VIT_TRAIN_RUN_LABEL} \\\n",
    "    --input-config default --input-config-file config.yaml --input-training . --input-test .\n",
    "dvc_create_stage --app-yaml ../../ex_vit/dvc_app.yaml --stage inference \\\n",
    "    --run-label ${VIT_INF_RUN_LABEL} \\\n",
    "    --input-config default --input-config-file config.yaml --input-training ${VIT_TRAIN_RUN_LABEL} --input-inference ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b50a3d-a9e5-43a9-aff9-dcd44fa351a4",
   "metadata": {},
   "source": [
    "## Running and monitoring training and inference with SLURM\n",
    "These stages can be inspected with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1141181e-6424-4c28-86c0-6c729fa25dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "dvc dag --dot config/ex_vit/cifar10/baseline_model/inference/${VIT_INF_RUN_LABEL}/dvc.yaml | tee config/ex_vit/cifar10/baseline_model/inference/${VIT_INF_RUN_LABEL}/dvc_dag.dot\n",
    "if [[ $(command -v dot) ]]; then\n",
    "    dot -Tsvg config/ex_vit/cifar10/baseline_model/inference/${VIT_INF_RUN_LABEL}/dvc_dag.dot > config/ex_vit/cifar10/baseline_model/inference/${VIT_INF_RUN_LABEL}/dvc_dag.svg\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587cc186-b78b-4df0-a900-713b4e4168b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvc_dag_img = 'config/ex_vit/cifar10/baseline_model/inference/' + os.environ['VIT_INF_RUN_LABEL'] + '/dvc_dag.svg'\n",
    "if os.path.exists(dvc_dag_img):\n",
    "    display(SVG(filename=dvc_dag_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5093f914-a50b-4ee0-b94e-579cf8ec5c82",
   "metadata": {},
   "source": [
    "And finally executed with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dec8894-90c8-432a-876c-443a77333032",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "dvc repro --no-commit config/ex_vit/cifar10/baseline_model/inference/${VIT_INF_RUN_LABEL}/dvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e6b615-cd91-4292-acdf-b8e5aeee21f5",
   "metadata": {},
   "source": [
    "The submitted SLURM stages can be monitored with a status file and log files in the `dvc.yaml` directory as well as the tool `dvc_scontrol` as familiar from the [SLURM tutorial](slurm_async_sim_tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511800fd-c6e4-46b5-8cc2-8ef16dbc0559",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc_scontrol show all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d1059e-8bbe-4212-a6d0-2457c3613ae9",
   "metadata": {},
   "source": [
    "As the stage and commit jobs are put on hold in order to enable the submission of more DVC SLURM stages by the user, we have to release them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6188114-319f-42de-9041-a24d9dad43be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc_scontrol release stage,commit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8fdb1f-116d-4d52-8d08-06f299b69c32",
   "metadata": {},
   "source": [
    "This will enable resource allocation and execution of the application stages. Upon successfull execution, the stage outputs will also be committed. We can now log out from the SLURM cluster and return later to inspect results.\n",
    "\n",
    "For the purpose of this notebook, however, we want to keep monitoring the pipeline on SLURM and wait for the completion of the last job, which is a DVC commit.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ad1039-2b47-413f-b53f-6e7a01bdea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# ID of last commit job\n",
    "commit_jobid=$(cat config/ex_vit/cifar10/baseline_model/inference/${VIT_INF_RUN_LABEL}/ex_vit_cifar10_baseline_model_inference_${VIT_INF_RUN_LABEL}.dvc_commit_jobid)\n",
    "../../slurm_wait_for_job.sh ${commit_jobid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e7364-2734-4b47-a0d9-19d080938585",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree {encrypt,config}/{in,ex_vit}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3533b106-1d54-461c-8b24-c7921c5eeb68",
   "metadata": {},
   "source": [
    "We will convince ourselves that the predicted labels are encrypted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc9ad95-7590-4228-a31e-aac319b729fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "os.environ['VIT_PREDICTED_LABELS'] = f\"ex_vit/cifar10/baseline_model/inference/{os.environ['VIT_INF_RUN_LABEL']}/output/predicted_labels.pkl\"\n",
    "\n",
    "def unpickle_and_print_labels(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'rb') as f:\n",
    "            predicted_labels = pickle.load(f)\n",
    "        print(\"Successfully unpickled labels:\")\n",
    "        print(predicted_labels)\n",
    "    except pickle.UnpicklingError:\n",
    "        print(f\"Error unpickling the file at {filepath}.\")\n",
    "\n",
    "unpickle_and_print_labels(os.path.join('encrypt', os.environ['VIT_PREDICTED_LABELS']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355507b7-efbc-4700-a96f-238cf2d20b1f",
   "metadata": {},
   "source": [
    "and that they can be read through the EncFS-layer (only for exposition, not to be performed on confidential data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7f02d0-9e40-4c63-bfa2-048ad688dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "!encfs_mount_and_run encrypt ${ENCFS_DECRYPT_DIR} /dev/null cp ${ENCFS_DECRYPT_DIR}/${VIT_PREDICTED_LABELS} predicted_labels.pkl >/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04720ae-74ec-407c-abf5-186fe0abe0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpickle_and_print_labels('predicted_labels.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1287334c-4367-4c02-8415-89a5500fa262",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm predicted_labels.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ae941b-fda2-4a23-8970-0108e483140a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
