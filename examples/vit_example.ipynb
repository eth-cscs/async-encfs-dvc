{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e1e3f1f-753d-462b-88bd-b31d918896c1",
   "metadata": {},
   "source": [
    "# Distributed training and inference with a Vision Transformer in PyTorch using EncFS and SLURM\n",
    "\n",
    "This application shows the concepts previously introduced in tutorials - DVC policies, EncFS and SLURM - in action with a [Vision Transformer](https://github.com/pytorch/examples/blob/main/vision_transformer) network from the PyTorch example collection that is applied to the CIFAR10 dataset. We first download the data to an encrypted directory, then perform distributed training and finally inference with the Vision Transformer. Even though we do not use containers here, an extension to use the Sarus container engine can be done without difficulty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f276f6c3-08cf-409b-b1e3-6e767e0e82db",
   "metadata": {},
   "source": [
    "## Initializing the DVC repository\n",
    "We first import the depencies for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af8552e-1d3e-4c31-b410-627b1de89fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import traceback\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac94128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG  # test_vit_example: skip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65be096-eb8e-4d18-a2e2-858ea136b47b",
   "metadata": {},
   "source": [
    "Create a new directory `data/v3` for the DVC root and change to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6dd315e-6ab4-4e75-8a85-4056b09563ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data/v3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5823a232-0796-405f-af6d-ecda49add286",
   "metadata": {},
   "source": [
    "Initialize an `encfs` DVC repository as explained in the [EncFS-simulation tutorial](encfs_sim_tutorial.ipynb) using the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "878f12d8-3b44-40f4-8bd2-ffb2dd84fa2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dvc_init_repo: Initializing DVC repo at /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3\n",
      "\u001b[34m2023-10-04 12:45:49,911\u001b[39m \u001b[34mDEBUG\u001b[39m: v0.1.dev8866+gd72e04c, CPython 3.9.4 on Linux-5.3.18-24.102-default-x86_64-with-glibc2.26\n",
      "\u001b[34m2023-10-04 12:45:49,911\u001b[39m \u001b[34mDEBUG\u001b[39m: command: /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/venv/bin/dvc init --subdir --verbose\n",
      "\u001b[34m2023-10-04 12:45:50,447\u001b[39m \u001b[34mDEBUG\u001b[39m: Added '/scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/.dvc/config.local' to gitignore file.\n",
      "\u001b[34m2023-10-04 12:45:50,448\u001b[39m \u001b[34mDEBUG\u001b[39m: Added '/scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/.dvc/tmp' to gitignore file.\n",
      "\u001b[34m2023-10-04 12:45:50,449\u001b[39m \u001b[34mDEBUG\u001b[39m: Added '/scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/.dvc/cache' to gitignore file.\n",
      "\u001b[34m2023-10-04 12:45:50,449\u001b[39m \u001b[34mDEBUG\u001b[39m: Removing '/var/tmp/dvc/repo/21533fdb769b0281e411ded44bd8c4cf'\n",
      "\u001b[34m2023-10-04 12:45:50,691\u001b[39m \u001b[34mDEBUG\u001b[39m: Staging files: {'/scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/.dvcignore', '/scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/.dvc/.gitignore', '/scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/.dvc/config'}\n",
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "\u001b[34m2023-10-04 12:45:50,785\u001b[39m \u001b[34mDEBUG\u001b[39m: Analytics is enabled.\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m        DVC has enabled anonymous aggregate usage analytics.         \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m     Read the analytics documentation (and how to opt-out) here:     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m             <\u001b[36mhttps://dvc.org/doc/user-guide/analytics\u001b[39m>              \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\n",
      "\u001b[33mWhat's next?\u001b[39m\n",
      "\u001b[33m------------\u001b[39m\n",
      "- Check out the documentation: <\u001b[36mhttps://dvc.org/doc\u001b[39m>\n",
      "- Get help and share ideas: <\u001b[36mhttps://dvc.org/chat\u001b[39m>\n",
      "- Star us on GitHub: <\u001b[36mhttps://github.com/iterative/dvc\u001b[39m>\n",
      "\u001b[34m2023-10-04 12:45:50,788\u001b[39m \u001b[34mDEBUG\u001b[39m: Analytics is enabled.\n",
      "\u001b[34m2023-10-04 12:45:50,871\u001b[39m \u001b[34mDEBUG\u001b[39m: Trying to spawn '['daemon', '-q', 'analytics', '/tmp/tmpx6eqgiyh']'\n",
      "\u001b[34m2023-10-04 12:45:50,872\u001b[39m \u001b[34mDEBUG\u001b[39m: Spawned '['daemon', '-q', 'analytics', '/tmp/tmpx6eqgiyh']'\n",
      "\u001b[0m\u001b[0m\u001b[0mdvc_init_repo: Initializing DVC repo (encfs) and stage policies.\n",
      "dvc_init_repo: Created directories for EncFS and DVC metadata:\n",
      "dvc_init_repo:   EncFS encrypt:  encrypt\n",
      "dvc_init_repo:   EncFS decrypt:  /tmp/encfs_25680_async_encfs_dvc_cc38b32792ae\n",
      "dvc_init_repo:   DVC metadata:   config\n",
      "dvc_init_repo: Initialization of encfs DVC repo complete\n"
     ]
    }
   ],
   "source": [
    "!dvc_init_repo . encfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c502c32-a686-4818-99ca-e3d1d040839e",
   "metadata": {},
   "source": [
    "As next step, EncFS needs to be configured, which can be achieved by running\n",
    "\n",
    "```shell\n",
    "${ENCFS_INSTALL_DIR}/bin/encfs -o allow_root,max_write=1048576,big_writes -f encrypt decrypt\n",
    "```\n",
    "as described in the [EncFS initialization instructions](../async_encfs_dvc/encfs_int/README.md).\n",
    "\n",
    "Here, only for the purpose of this tutorial, we use a pre-established configuration with a simple password. It is important that this is only for demonstration purposes - in practice always generate a **random** key and store it in a **safe location**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aa7bed3-2011-4a48-a94b-1798f76edcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo 1234 > encfs_tutorial.key\n",
    "cp $(git rev-parse --show-toplevel)/examples/.encfs6.xml.tutorial encrypt/ && mv encrypt/.encfs6.xml.tutorial encrypt/.encfs6.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30981619-edde-406b-8a4a-74340a078b42",
   "metadata": {},
   "source": [
    "At runtime, EncFS will read the password from a file. The location of that file is passed in an environment variable that has to be set when `dvc repro` is run on a stage or `encfs_launch` is used to e.g. inspect the encrypted data interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc404dba-7668-4037-9b12-9d9755967e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ENCFS_PW_FILE'] = os.path.realpath('encfs_tutorial.key')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6e1e70-9135-4c7c-954f-af0c5b850341",
   "metadata": {},
   "source": [
    "The DVC repo has been initialized with repo and stage policies available under `.dvc_policies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d25ced6-1813-4891-895a-8963bb46a96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.dvc_policies\u001b[00m\n",
      "├── \u001b[01;34mrepo\u001b[00m\n",
      "│   └── dvc_root.yaml\n",
      "└── \u001b[01;34mstages\u001b[00m\n",
      "    ├── dvc_config.yaml\n",
      "    ├── dvc_etl.yaml\n",
      "    ├── dvc_in.yaml\n",
      "    ├── dvc_ml_inference.yaml\n",
      "    ├── dvc_ml_training.yaml\n",
      "    └── dvc_simulation.yaml\n",
      "\n",
      "2 directories, 7 files\n"
     ]
    }
   ],
   "source": [
    "!tree .dvc_policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aaefd1-e2d6-4322-a02c-7937db59870d",
   "metadata": {},
   "source": [
    "For the purpose of this tutorial, we will extract the paths of the encrypted directory and the mount target of EncFS into environment variables. This is not a necessary step to run DVC stages with EncFS, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f1a40b-15b0-4e53-b16f-50ec24a4909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from async_encfs_dvc.encfs_int.mount_config import load_mount_config\n",
    "\n",
    "mount_config = [os.popen(f\"echo {d}\").read().strip() for d in  # evaluating shell exprs in paths\n",
    "                load_mount_config('.dvc_policies/repo/dvc_root.yaml')]\n",
    "\n",
    "os.environ['ENCFS_ENCRYPT_DIR'] = mount_config[0]  # encrypt (same on all hosts)\n",
    "os.environ['ENCFS_DECRYPT_DIR'] = mount_config[1]  # host-specific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c1eae6-bdeb-491c-a3dc-1d8ae82b6e6c",
   "metadata": {},
   "source": [
    "## Fetching the input dataset\n",
    "Our pipeline will be based on the CIFAR10 dataset. For the purpose of this example, we will use the test dataset also as an input at the inference stage. The CIFAR10 dataset requires training and test dataset to be co-located. Therefore, we will not use the same fine-grained DVC file hierarchy as in the ML tutorial, where for each of training, test and inference the original and preprocessed data was grouped. We download the dataset using the code in `ex_in` and track it with DVC using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "689647a9-2b5a-4f59-b153-b10147ccec15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CIFAR10_IN_RUN_LABEL=init\n"
     ]
    }
   ],
   "source": [
    "%env CIFAR10_IN_RUN_LABEL=init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61fa28d0-9aa6-4847-aa0d-53f40385ccba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing DVC stage to config/in/cifar10/original\n",
      "Using encfs - don't forget to set ENCFS_PW_FILE/ENCFS_INSTALL_DIR when running 'dvc repro --no-commit --no-lock'.\n",
      "Added stage 'in_original_fetch_cifar10_init' in 'dvc.yaml'            core\u001b[39m>\n",
      "\u001b[0mAdded `dvc_app.yaml` to Git staging area.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc_create_stage --app-yaml ../../ex_in/dvc_app.yaml --stage fetch_cifar10 --run-label ${CIFAR10_IN_RUN_LABEL}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525a331d-ac6d-464a-805f-9ce38de6222e",
   "metadata": {},
   "source": [
    "This stage can be executed, frozen upon success and the resulting file hierarchy inspected with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "102870a6-3156-4b36-b72e-b368dca773e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running stage 'config/in/cifar10/original/dvc.yaml:in_original_fetch_cifar10_init':\n",
      "> dvc_cmd in_original_fetch_cifar10_init slurm_enqueue.sh in_original_fetch_cifar10_init dvc_app.yaml fetch_cifar10 encfs_mount_and_run ../../../../encrypt /tmp/encfs_25680_async_encfs_dvc_in_original_fetch_cifar10_init_9127b8ee0785_cc38b32792ae ../../../../../../../../../../../../tmp/encfs_25680_async_encfs_dvc_in_original_fetch_cifar10_init_9127b8ee0785_cc38b32792ae/in/cifar10/original/output/encfs_out_{MPI_RANK}.log bash -c \"$(git rev-parse --show-toplevel)/examples/ex_in/fetch_cifar10.py --in-output /tmp/encfs_25680_async_encfs_dvc_in_original_fetch_cifar10_init_9127b8ee0785_cc38b32792ae/in/cifar10/original/output\" \n",
      "slurm_enqueue.sh[in_original_fetch_cifar10_init]: Info: Putting any concurrent dvc commit or push operations on hold (use dvc_scontrol release later). Warning: Concurrent dvc operations cause a potential conflict for acquiring ../../../../.dvc/tmp/rwlock) and dvc commands (incl. repro) will error out if they detect this.\n",
      "dvc_scontrol: All jobs of lukasd held. To make sure that no other users run DVC commands on this repo use 'dvc_scontrol show commit'.\n",
      "dvc_scontrol: All jobs of lukasd held. To make sure that no other users run DVC commands on this repo use 'dvc_scontrol show push'.\n",
      "slurm_enqueue.sh[in_original_fetch_cifar10_init]: DVC stage deps of in_original_fetch_cifar10_init: \n",
      "slurm_enqueue.sh[in_original_fetch_cifar10_init]: DVC stage outs of in_original_fetch_cifar10_init: ../../../../encrypt/in/cifar10/original/output output\n",
      "slurm_enqueue.sh[in_original_fetch_cifar10_init]: Cannot find running/committed stage in_original_fetch_cifar10_init - submitting it.\n",
      "slurm_enqueue.sh[in_original_fetch_cifar10_init]: Launching asynchronous stage in_original_fetch_cifar10_init with SLURM\n",
      "slurm_enqueue.sh[in_original_fetch_cifar10_init]: Submit push job for in_original_fetch_cifar10_init manually with slurm_enqueue_dvc_push_in_original_fetch_cifar10_init.sh.\n",
      "slurm_enqueue.sh[in_original_fetch_cifar10_init]: Submitted all jobs for stage in_original_fetch_cifar10_init (stage: 49288748, cleanup: 49288749, commit: 49288750).\n",
      "slurm_enqueue.sh[in_original_fetch_cifar10_init]: All jobs submitted on hold to enable further DVC usage. When ready, use 'scontrol release <job-id1> <job-id2> ...' to selectively unblock invidual jobs or 'dvc_scontrol release (stage|commit|push)' to unblock all jobs of particular type in this DVC repo.\n",
      "\u001b[33mWARNING\u001b[39m: 'encrypt/in/cifar10/original/output' is empty.     core\u001b[39m>\n",
      "Use `dvc commit` and `dvc push` to send your updates to remote storage.         \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc repro --no-commit --no-lock config/in/cifar10/original/dvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a090117-4ed9-4e3c-abd2-6f8fc0790b4f",
   "metadata": {},
   "source": [
    "As an asynchronous SLURM stage, we have to wait for its completion until we can inspect the data. As shown in the [SLURM tutorial](slurm_async_sim_tutorial.ipynb), this includes first releasing the stage and commit jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63dc32ff-9a29-40d7-ad1f-8a36cfe654d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dvc_scontrol: Releasing job dvc_in_original_fetch_cifar10_init_cc38b32792ae[sbatch_dvc_stage_in_original_fetch_cifar10_init.sh] (reason JobHeldUser) at 49288748.\n",
      "dvc_scontrol: Releasing job dvc_op_cc38b32792ae[sbatch_dvc_commit.sh] (reason JobHeldUser) at 49288750.\n"
     ]
    }
   ],
   "source": [
    "!dvc_scontrol release stage,commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd99c7fe-b8a5-4461-bbc9-e8be32d2cd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring SLURM job 49288750.\n",
      "The SLURM pipeline is still in process.\n",
      "dvc_scontrol: DVC stage jobs:\n",
      "           USER           JOBID     REASON       TIME  TIME_LEFT                                                         NAME                                                                                                                           WORK_DIR\n",
      "         lukasd        49288748       None       0:28    3:59:32              dvc_in_original_fetch_cifar10_init_cc38b32792ae                                      /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/config/in/cifar10/original\n",
      "dvc_scontrol: DVC commit jobs:\n",
      "           USER           JOBID     REASON       TIME  TIME_LEFT                                                         NAME                                                                                                                           WORK_DIR\n",
      "         lukasd        49288750 Dependency       0:00    4:00:00                                          dvc_op_cc38b32792ae                                      /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/config/in/cifar10/original\n",
      "The SLURM pipeline is still in process.\n",
      "dvc_scontrol: DVC stage jobs:\n",
      "           USER           JOBID     REASON       TIME  TIME_LEFT                                                         NAME                                                                                                                           WORK_DIR\n",
      "dvc_scontrol: DVC commit jobs:\n",
      "           USER           JOBID     REASON       TIME  TIME_LEFT                                                         NAME                                                                                                                           WORK_DIR\n",
      "         lukasd        49288750       None       0:42    3:59:18                                          dvc_op_cc38b32792ae                                      /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/config/in/cifar10/original\n",
      "The SLURM pipeline has successfully completed.\n"
     ]
    }
   ],
   "source": [
    "!../../slurm_wait_for_job.sh $(cat config/in/cifar10/original/in_original_fetch_cifar10_${CIFAR10_IN_RUN_LABEL}.dvc_commit_jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc792f8-876f-44f8-8d4a-20318f9c18be",
   "metadata": {},
   "source": [
    "As we do not expect this dataset to change, we can freeze this input stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "547f74da-016e-4572-940c-d541ed40fadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modifying stage 'in_original_fetch_cifar10_init' in 'config/in/cifar10/original/dvc.yaml'\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc freeze config/in/cifar10/original/dvc.yaml:in_original_fetch_cifar10_${CIFAR10_IN_RUN_LABEL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "175b2669-395f-472a-8bdc-ace04b4b29f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mencrypt/in\u001b[00m\n",
      "└── \u001b[01;34mcifar10\u001b[00m\n",
      "    └── \u001b[01;34moriginal\u001b[00m\n",
      "        └── \u001b[01;34moutput\u001b[00m\n",
      "            ├── \u001b[01;34mcifar-10-batches-py\u001b[00m\n",
      "            │   ├── batches.meta\n",
      "            │   ├── data_batch_1\n",
      "            │   ├── data_batch_2\n",
      "            │   ├── data_batch_3\n",
      "            │   ├── data_batch_4\n",
      "            │   ├── data_batch_5\n",
      "            │   ├── readme.html\n",
      "            │   └── test_batch\n",
      "            ├── \u001b[01;31mcifar-10-python.tar.gz\u001b[00m\n",
      "            └── encfs_out_0.log\n",
      "\u001b[01;34mconfig\u001b[00m\n",
      "└── \u001b[01;34min\u001b[00m\n",
      "    └── \u001b[01;34mcifar10\u001b[00m\n",
      "        └── \u001b[01;34moriginal\u001b[00m\n",
      "            ├── dvc_app.yaml\n",
      "            ├── dvc.lock\n",
      "            ├── dvc_sbatch.dvc_commit.49288750.err\n",
      "            ├── dvc_sbatch.dvc_commit.49288750.out\n",
      "            ├── dvc.yaml\n",
      "            ├── in_original_fetch_cifar10_init.dvc_cleanup_jobid\n",
      "            ├── in_original_fetch_cifar10_init.dvc_commit_jobid\n",
      "            ├── in_original_fetch_cifar10_init.dvc_stage_jobid\n",
      "            ├── \u001b[01;34moutput\u001b[00m\n",
      "            │   ├── dvc_sbatch.dvc_in_original_fetch_cifar10_init_cc38b32792ae.49288748.out\n",
      "            │   └── dvc_stage_out.log\n",
      "            ├── \u001b[01;32msbatch_dvc_stage_in_original_fetch_cifar10_init.sh\u001b[00m\n",
      "            └── \u001b[01;32mslurm_enqueue_dvc_push_in_original_fetch_cifar10_init.sh\u001b[00m\n",
      "\n",
      "8 directories, 22 files\n"
     ]
    }
   ],
   "source": [
    "!tree encrypt/in config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb09321-fa1c-4141-b265-736a9c391ef2",
   "metadata": {},
   "source": [
    "We convince ourselves that the data is encrypted as demonstrated in the [EncFS-simulation tutorial](encfs_sim_tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baf58fa5-6bb2-472f-8d0f-3eb3bc793dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0001ğ�\n",
      "��=��\u001c",
      "��Q\u0018\u001aJ!!��w==�\u0013\u000f��gX4\u000f�g���5\u0017��\u0005��B,]4�k���ٺq\u0006�Ւ�g\u0001�\u0019"
     ]
    }
   ],
   "source": [
    "!head encrypt/in/cifar10/original/output/cifar-10-batches-py/readme.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0223c531-0833-4f95-bf25-a1ca84b9279e",
   "metadata": {},
   "source": [
    "whereas it can readily be inspected with EncFS (*never* handle confidential data in this way, always use `encfs_launch` as advised in the EncFS-tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90cbf6a1-3d65-459f-b766-6998139c8bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<meta HTTP-EQUIV=\"REFRESH\" content=\"0; url=http://www.cs.toronto.edu/~kriz/cifar.html\">\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "encfs_mount_and_run encrypt ${ENCFS_DECRYPT_DIR} /dev/null cp ${ENCFS_DECRYPT_DIR}/in/cifar10/original/output/cifar-10-batches-py/readme.html readme.html >/dev/null\n",
    "head readme.html\n",
    "rm readme.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c3900-edd2-4cb0-8fb1-1fcba605624a",
   "metadata": {},
   "source": [
    "The execution of the data fetch stage can also be deferred to the ML stages, where it will be triggered as a dependency.\n",
    "\n",
    "Before moving to the next stage, we define execution labels based on timestamps for the subsequent DVC stages. In a real-world application, the timestamps would usually be generated on the fly when creating the DVC stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cae5a9cc-eee6-4c68-b9fe-46e195a0619c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: VIT_TRAIN_RUN_LABEL=run_20230721_081756\n",
      "env: VIT_INF_RUN_LABEL=run_20230721_115412\n"
     ]
    }
   ],
   "source": [
    "%env VIT_TRAIN_RUN_LABEL=run_20230721_081756\n",
    "%env VIT_INF_RUN_LABEL=run_20230721_115412"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b9e318-748a-4d20-a90b-f352e23dcca7",
   "metadata": {},
   "source": [
    "The next step usually involves setting up preprocessing stages. In the Vision Transformer example, this corresponds to resizing the images. Since this is an inexpensive operation and comes integrated with the training and inference in the publicly available code, we will skip this. For instructions on how to define a separate preprocessing step, please refer to the [ML repository tutorial](ml_tutorial.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae24d37d-9dd0-4d70-8bc9-6517043afef6",
   "metadata": {},
   "source": [
    "## Creating the distributed training and inference stages\n",
    "Now, we are ready to set up the stages for the Vision Transformer model based on the CIFAR10 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "262b4837-26cc-42f2-b380-93622d07a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p {encrypt,config}/ex_vit/cifar10/baseline_model/{training,inference,config}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22280d7e-cae3-4df3-8674-2201925fceeb",
   "metadata": {},
   "source": [
    "We capture the model configuration and output under the name `baseline_model` to refer to the publicly available model. The default values for hyperparameters and model architecture specification are encapsulated in a file `config.yaml`. We commit this file to the DVC repository using a `config` stage analogous to the manual input stage for datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cb9a2f8-be4f-426f-9bbb-ab956ac03c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: app argument --config-file not set (using Jinja2 default in app YAML if not --strict-mode).\n",
      "Not using SLURM or MPI in this DVC stage.\n",
      "Writing DVC stage to config/ex_vit/cifar10/baseline_model/config/default\n",
      "Using encfs - don't forget to set ENCFS_PW_FILE/ENCFS_INSTALL_DIR when running 'dvc repro'.\n",
      "Added stage 'ex_vit_cifar10_baseline_model_config_init' in 'dvc.yaml' core\u001b[39m>\n",
      "\u001b[0mAdded `dvc_app.yaml` to Git staging area.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc_create_stage --app-yaml ../../ex_vit/dvc_app.yaml --stage config --run-label init --config-group default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae707af8-e6c8-4131-bb7a-5daec3866932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running stage 'config/ex_vit/cifar10/baseline_model/config/default/dvc.yaml:ex_vit_cifar10_baseline_model_config_init':\n",
      "> dvc_cmd ex_vit_cifar10_baseline_model_config_init encfs_mount_and_run ../../../../../../encrypt /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_config_init_a4d080c0c41c_cc38b32792ae ../../../../../../../../../../../../../../tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_config_init_a4d080c0c41c_cc38b32792ae/ex_vit/cifar10/baseline_model/config/default/output/encfs_out_{MPI_RANK}.log bash -c \"$(git rev-parse --show-toplevel)/examples/ex_vit/copy_config.sh --dest /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_config_init_a4d080c0c41c_cc38b32792ae/ex_vit/cifar10/baseline_model/config/default/output --source $(git rev-parse --show-toplevel)/examples/ex_vit/config.yaml\" \n",
      "encfs_mount_and_run[../../../../../../encrypt->/tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_config_init_a4d080c0c41c_cc38b32792ae]: Unable to determine local MPI rank - assuming to run in non-distributed mode (as a single process).\n",
      "encfs_mount_and_run[../../../../../../encrypt->/tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_config_init_a4d080c0c41c_cc38b32792ae]: Rank 0 on daint101: Running encfs-mount at /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_config_init_a4d080c0c41c_cc38b32792ae.\n",
      "encfs_mount_and_run[../../../../../../encrypt->/tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_config_init_a4d080c0c41c_cc38b32792ae]: total 8.0K\n",
      "drwxr-xr-x 3 lukasd csstaff 4.0K  4. Okt 12:48 ex_vit\n",
      "drwxr-xr-x 3 lukasd csstaff 4.0K  4. Okt 12:45 in\n",
      "encfs_mount_and_run[../../../../../../encrypt->/tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_config_init_a4d080c0c41c_cc38b32792ae]: Rank 0 on daint101: Successfully mounted encfs-dir at /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_config_init_a4d080c0c41c_cc38b32792ae and wrote to sync-file /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/encrypt/.encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_config_init_a4d080c0c41c_cc38b32792ae_daint101_local_sync - starting encfs-job\n",
      "encfs_mount_and_run[../../../../../../encrypt->/tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_config_init_a4d080c0c41c_cc38b32792ae]: Rank 0 on daint101: encfs-job completed.\n",
      "encfs_mount_and_run[../../../../../../encrypt->/tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_config_init_a4d080c0c41c_cc38b32792ae]: Rank 0 on daint101: sync-file content is 0 - entering wait-loop.\n",
      "encfs_mount_and_run[../../../../../../encrypt->/tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_config_init_a4d080c0c41c_cc38b32792ae]: Rank 0 on daint101: sync-file content is 0 - all local ranks finished encfs-job, unmounting encfs.\n",
      "encfs_mount_and_run[../../../../../../encrypt->/tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_config_init_a4d080c0c41c_cc38b32792ae]: Filesystem unmounting: /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_config_init_a4d080c0c41c_cc38b32792ae\n",
      "Generating lock file 'config/ex_vit/cifar10/baseline_model/config/default/dvc.lock'\n",
      "Updating lock file 'config/ex_vit/cifar10/baseline_model/config/default/dvc.lock'\n",
      "Use `dvc push` to send your updates to remote storage.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc repro config/ex_vit/cifar10/baseline_model/config/default/dvc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f177211-b430-468e-aa08-aca63277e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mencrypt/ex_vit\u001b[00m\n",
      "└── \u001b[01;34mcifar10\u001b[00m\n",
      "    └── \u001b[01;34mbaseline_model\u001b[00m\n",
      "        ├── \u001b[01;34mconfig\u001b[00m\n",
      "        │   └── \u001b[01;34mdefault\u001b[00m\n",
      "        │       └── \u001b[01;34moutput\u001b[00m\n",
      "        │           ├── config.yaml\n",
      "        │           └── encfs_out_0.log\n",
      "        ├── \u001b[01;34minference\u001b[00m\n",
      "        └── \u001b[01;34mtraining\u001b[00m\n",
      "\u001b[01;34mconfig/ex_vit\u001b[00m\n",
      "└── \u001b[01;34mcifar10\u001b[00m\n",
      "    └── \u001b[01;34mbaseline_model\u001b[00m\n",
      "        ├── \u001b[01;34mconfig\u001b[00m\n",
      "        │   └── \u001b[01;34mdefault\u001b[00m\n",
      "        │       ├── dvc_app.yaml\n",
      "        │       ├── dvc.lock\n",
      "        │       ├── dvc.yaml\n",
      "        │       └── \u001b[01;34moutput\u001b[00m\n",
      "        │           └── dvc_stage_out.log\n",
      "        ├── \u001b[01;34minference\u001b[00m\n",
      "        └── \u001b[01;34mtraining\u001b[00m\n",
      "\n",
      "14 directories, 6 files\n"
     ]
    }
   ],
   "source": [
    "!tree {encrypt,config}/ex_vit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92da4a45-331a-4a9c-8efa-33758d294102",
   "metadata": {},
   "source": [
    "Following this, we can set up the training and inference stages. Where necessary, we can obtain completion suggestions with `--show-opts`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c23763a0-4602-4932-895e-0967304ecb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: stage argument --input-training-file not set (using Jinja2 default in app YAML if not --strict-mode).\n",
      "Warning: stage argument --input-test-file not set (using Jinja2 default in app YAML if not --strict-mode).\n",
      "Writing DVC stage to config/ex_vit/cifar10/baseline_model/training/run_20230721_081756\n",
      "Using encfs - don't forget to set ENCFS_PW_FILE/ENCFS_INSTALL_DIR when running 'dvc repro --no-commit --no-lock'.\n",
      "Added stage 'ex_vit_cifar10_baseline_model_training_run_20230721_081756' in 'dvc.yaml'\n",
      "Added `dvc_app.yaml` to Git staging area.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "dvc_create_stage --app-yaml ../../ex_vit/dvc_app.yaml --stage training \\\n",
    "    --run-label ${VIT_TRAIN_RUN_LABEL} \\\n",
    "    --input-config default --input-config-file config.yaml --input-training . --input-test ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6407e19-7213-4419-b5a3-7ba1bbb8f1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# PyTorch Vision Transformer description for DVC stage generation\n",
      "\n",
      "app:\n",
      "  name: &app_name ex_vit/cifar10/baseline_model  # apps should always be versioned, dataset can be absorbed into model in case of redundancy\n",
      "  code_root: &code_root \"\\\\$(git rev-parse --show-toplevel)/examples/ex_vit\"  # /src/app\n",
      "\n",
      "  # defaults for SLURM, can be overriden in merged mappings\n",
      "  slurm_defaults: &slurm_defaults\n",
      "    # environment configuration in sbatch script before srun (only stage supported)\n",
      "    stage_env: |\n",
      "      module load daint-gpu\n",
      "      module load PyTorch\n",
      "      export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
      "\n",
      "      # Environment variables needed by the NCCL backend for distributed training\n",
      "      export NCCL_DEBUG=INFO\n",
      "      export NCCL_IB_HCA=ipogif0\n",
      "      export NCCL_IB_CUDA_SUPPORT=1\n",
      "    dvc:  # sbatch options\n",
      "      --cpus-per-task: 24\n",
      "      --constraint: mc\n",
      "      --time: '4:00:00'\n",
      "    all:  # sbatch options\n",
      "      --account: csstaff\n",
      "\n",
      "  stages: # app-specific stages\n",
      "    training:\n",
      "      type: ml_training_stage\n",
      "      script: [*code_root, training.py]\n",
      "      input_training: # parameterizes training data dep\n",
      "        name: &input_training_app_name in/cifar10\n",
      "        stage: &input_training_app_stage original\n",
      "      input_test: # parameterizes test data dep\n",
      "        name: &input_test_app_name in/cifar10\n",
      "        stage: &input_test_app_stage original\n",
      "      extra_command_line_options:\n",
      "        --dist: ~\n",
      "        --dry-run: ~\n",
      "        # --no-cuda: ~\n",
      "\n",
      "      slurm_opts:  # run with SLURM\n",
      "        <<: *slurm_defaults\n",
      "        stage:  # sbatch options\n",
      "          --nodes: 4\n",
      "          --ntasks: 4\n",
      "          --cpus-per-task: 12\n",
      "          --constraint: gpu\n",
      "          --time: '12:00:00'\n",
      "\n",
      "include:\n",
      "  dvc_root: '.dvc_policies/repo/dvc_root.yaml'\n",
      "  ml_training_stage: '.dvc_policies/stages/dvc_ml_training.yaml'\n",
      "\n",
      "# DVC repo configuration with encfs-encryption\n",
      "\n",
      "host_data:\n",
      "  dvc_root: &dvc_root_host ../..  # output of `dvc root`\n",
      "  dvc_config: &dvc_config_host config\n",
      "  mount:  # relative to dvc_root_host\n",
      "    data:\n",
      "      type: encfs\n",
      "      origin: encrypt\n",
      "      default_target: &mount_data_host decrypt  # make sure this is a dvc-repo-specific path if it is absolute\n",
      "      custom_target:  # machine-specific\n",
      "        - machine: ['daint[\\d]+', 'nid[\\d]+'] # TODO: Alps\n",
      "          target: /tmp/encfs_$(id -u)_async_encfs_dvc  # make sure this is a dvc-repo-specific path if using multiple encfs-repos\n",
      "\n",
      "# A generic ML training stage\n",
      "# All values are interpreted as paths relative to the host/container data (encfs) mount point\n",
      "# Exercise: implement stage policy for continuing training from a saved checkpoint by adding \n",
      "# another input depedency on saved model (this trains from scratch) \n",
      "\n",
      "ml_training_stage:  # stage_data is relative to mount data point\n",
      "  input:  # input data dependencies\n",
      "    training:  # training data\n",
      "      stage_data: &input_training_data [*input_training_app_name, *input_training_app_stage, \".\", output]\n",
      "      command_line_options:  # for script\n",
      "        --training-input: [*input_training_data, \"\"]\n",
      "\n",
      "    test:  # test data\n",
      "      stage_data: &input_test_data [*input_test_app_name, *input_test_app_stage, \".\", output]\n",
      "      command_line_options:\n",
      "        --test-input: [*input_test_data, \"\"]\n",
      "\n",
      "    config:  # hyperparameter config\n",
      "      stage_data: &input_config [*app_name, config, \"default\", output]\n",
      "      command_line_options:\n",
      "        --config: [*input_config, \"config.yaml\"]\n",
      "\n",
      "  output:  # trained model\n",
      "    training:\n",
      "      stage_data: &output_training [*app_name, training, \"run_20230721_081756\", output]\n",
      "      command_line_options:\n",
      "        --training-output: *output_training\n",
      "\n",
      "  dvc: [*output_training, \"..\"]  # dvc.yaml storage location\n",
      "\n",
      "original:\n",
      "  file: \"$(dvc root)/../../ex_vit/23-10-04_12-48-58_daint101_lukasd_dvc_app.yaml\"  # source of this DVC app stage configuration\n",
      "  run_label: \"run_20230721_081756\"  # original run_label used\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat config/ex_vit/cifar10/baseline_model/training/run_20230721_081756/dvc_app.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b836ef8-0d2d-4982-ba75-91ac9bbc8c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stages:\n",
      "  ex_vit_cifar10_baseline_model_training_run_20230721_081756:\n",
      "    desc: Generated with venv/bin/dvc_create_stage --app-yaml ../../ex_vit/dvc_app.yaml\n",
      "      --stage training --run-label run_20230721_081756 --input-config default --input-config-file\n",
      "      config.yaml --input-training . --input-test . at commit f345163b81a65a2f7abf8630967f34ce628a56d0\n",
      "    cmd: 'dvc_cmd ex_vit_cifar10_baseline_model_training_run_20230721_081756 slurm_enqueue.sh\n",
      "      ex_vit_cifar10_baseline_model_training_run_20230721_081756 dvc_app.yaml training\n",
      "      encfs_mount_and_run ../../../../../../encrypt /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_training_run_20230721_081756_8d48e64a10c6_cc38b32792ae\n",
      "      ../../../../../../../../../../../../../../tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_training_run_20230721_081756_8d48e64a10c6_cc38b32792ae/ex_vit/cifar10/baseline_model/training/run_20230721_081756/output/encfs_out_{MPI_RANK}.log\n",
      "      bash -c \"$(git rev-parse --show-toplevel)/examples/ex_vit/training.py --training-input\n",
      "      /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_training_run_20230721_081756_8d48e64a10c6_cc38b32792ae/in/cifar10/original/output\n",
      "      --test-input /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_training_run_20230721_081756_8d48e64a10c6_cc38b32792ae/in/cifar10/original/output\n",
      "      --config /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_training_run_20230721_081756_8d48e64a10c6_cc38b32792ae/ex_vit/cifar10/baseline_model/config/default/output/config.yaml\n",
      "      --training-output /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_training_run_20230721_081756_8d48e64a10c6_cc38b32792ae/ex_vit/cifar10/baseline_model/training/run_20230721_081756/output\n",
      "      --dist --dry-run\" '\n",
      "    deps:\n",
      "    - ../../../../../../encrypt/ex_vit/cifar10/baseline_model/config/default/output\n",
      "    - ../../../../../../encrypt/in/cifar10/original/output\n",
      "    outs:\n",
      "    - ../../../../../../encrypt/ex_vit/cifar10/baseline_model/training/run_20230721_081756/output:\n",
      "        persist: true\n",
      "    - output:\n",
      "        persist: true\n"
     ]
    }
   ],
   "source": [
    "!cat config/ex_vit/cifar10/baseline_model/training/run_20230721_081756/dvc.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "482680bf-6939-4f0e-a434-7fa94d501736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: stage argument --input-training-file not set (using Jinja2 default in app YAML if not --strict-mode).\n",
      "Warning: stage argument --input-inference-file not set (using Jinja2 default in app YAML if not --strict-mode).\n",
      "Writing DVC stage to config/ex_vit/cifar10/baseline_model/inference/run_20230721_115412\n",
      "Using encfs - don't forget to set ENCFS_PW_FILE/ENCFS_INSTALL_DIR when running 'dvc repro --no-commit --no-lock'.\n",
      "Added stage 'ex_vit_cifar10_baseline_model_inference_run_20230721_115412' in 'dvc.yaml'\n",
      "Added `dvc_app.yaml` to Git staging area.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "dvc_create_stage --app-yaml ../../ex_vit/dvc_app.yaml --stage inference \\\n",
    "    --run-label ${VIT_INF_RUN_LABEL} \\\n",
    "    --input-config default --input-config-file config.yaml --input-training ${VIT_TRAIN_RUN_LABEL} --input-inference ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b50a3d-a9e5-43a9-aff9-dcd44fa351a4",
   "metadata": {},
   "source": [
    "## Running and monitoring the pipeline with SLURM\n",
    "These stages can be inspected with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1141181e-6424-4c28-86c0-6c729fa25dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strict digraph  {\n",
      "\"config/ex_vit/cifar10/baseline_model/config/default/dvc.yaml:ex_vit_cifar10_baseline_model_config_init\";\n",
      "\"config/ex_vit/cifar10/baseline_model/inference/run_20230721_115412/dvc.yaml:ex_vit_cifar10_baseline_model_inference_run_20230721_115412\";\n",
      "\"config/ex_vit/cifar10/baseline_model/training/run_20230721_081756/dvc.yaml:ex_vit_cifar10_baseline_model_training_run_20230721_081756\";\n",
      "\"config/in/cifar10/original/dvc.yaml:in_original_fetch_cifar10_init\";\n",
      "\"config/ex_vit/cifar10/baseline_model/config/default/dvc.yaml:ex_vit_cifar10_baseline_model_config_init\" -> \"config/ex_vit/cifar10/baseline_model/inference/run_20230721_115412/dvc.yaml:ex_vit_cifar10_baseline_model_inference_run_20230721_115412\";\n",
      "\"config/ex_vit/cifar10/baseline_model/config/default/dvc.yaml:ex_vit_cifar10_baseline_model_config_init\" -> \"config/ex_vit/cifar10/baseline_model/training/run_20230721_081756/dvc.yaml:ex_vit_cifar10_baseline_model_training_run_20230721_081756\";\n",
      "\"config/ex_vit/cifar10/baseline_model/training/run_20230721_081756/dvc.yaml:ex_vit_cifar10_baseline_model_training_run_20230721_081756\" -> \"config/ex_vit/cifar10/baseline_model/inference/run_20230721_115412/dvc.yaml:ex_vit_cifar10_baseline_model_inference_run_20230721_115412\";\n",
      "\"config/in/cifar10/original/dvc.yaml:in_original_fetch_cifar10_init\" -> \"config/ex_vit/cifar10/baseline_model/inference/run_20230721_115412/dvc.yaml:ex_vit_cifar10_baseline_model_inference_run_20230721_115412\";\n",
      "\"config/in/cifar10/original/dvc.yaml:in_original_fetch_cifar10_init\" -> \"config/ex_vit/cifar10/baseline_model/training/run_20230721_081756/dvc.yaml:ex_vit_cifar10_baseline_model_training_run_20230721_081756\";\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "dvc dag --dot config/ex_vit/cifar10/baseline_model/inference/${VIT_INF_RUN_LABEL}/dvc.yaml | tee config/ex_vit/cifar10/baseline_model/inference/${VIT_INF_RUN_LABEL}/dvc_dag.dot\n",
    "if [[ $(command -v dot) ]]; then\n",
    "    dot -Tsvg config/ex_vit/cifar10/baseline_model/inference/${VIT_INF_RUN_LABEL}/dvc_dag.dot > config/ex_vit/cifar10/baseline_model/inference/${VIT_INF_RUN_LABEL}/dvc_dag.svg\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "587cc186-b78b-4df0-a900-713b4e4168b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvc_dag_img = 'config/ex_vit/cifar10/baseline_model/inference/' + os.environ['VIT_INF_RUN_LABEL'] + '/dvc_dag.svg'  # test_vit_example: skip\n",
    "if os.path.exists(dvc_dag_img):  # test_vit_example: skip\n",
    "    display(SVG(filename=dvc_dag_img))  # test_vit_example: skip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5093f914-a50b-4ee0-b94e-579cf8ec5c82",
   "metadata": {},
   "source": [
    "And finally executed with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dec8894-90c8-432a-876c-443a77333032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 'config/ex_vit/cifar10/baseline_model/config/default/dvc.yaml:ex_vit_cifar10_baseline_model_config_init' didn't change, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: stage: 'config/in/cifar10/original/dvc.yaml:in_original_fetch_cifar10_init' is frozen. Its dependencies are not going to be reproduced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 'config/in/cifar10/original/dvc.yaml:in_original_fetch_cifar10_init' didn't change, skipping\n",
      "Running stage 'config/ex_vit/cifar10/baseline_model/training/run_20230721_081756/dvc.yaml:ex_vit_cifar10_baseline_model_training_run_20230721_081756':\n",
      "> dvc_cmd ex_vit_cifar10_baseline_model_training_run_20230721_081756 slurm_enqueue.sh ex_vit_cifar10_baseline_model_training_run_20230721_081756 dvc_app.yaml training encfs_mount_and_run ../../../../../../encrypt /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_training_run_20230721_081756_8d48e64a10c6_cc38b32792ae ../../../../../../../../../../../../../../tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_training_run_20230721_081756_8d48e64a10c6_cc38b32792ae/ex_vit/cifar10/baseline_model/training/run_20230721_081756/output/encfs_out_{MPI_RANK}.log bash -c \"$(git rev-parse --show-toplevel)/examples/ex_vit/training.py --training-input /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_training_run_20230721_081756_8d48e64a10c6_cc38b32792ae/in/cifar10/original/output --test-input /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_training_run_20230721_081756_8d48e64a10c6_cc38b32792ae/in/cifar10/original/output --config /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_training_run_20230721_081756_8d48e64a10c6_cc38b32792ae/ex_vit/cifar10/baseline_model/config/default/output/config.yaml --training-output /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_training_run_20230721_081756_8d48e64a10c6_cc38b32792ae/ex_vit/cifar10/baseline_model/training/run_20230721_081756/output --dist --dry-run\" \n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_training_run_20230721_081756]: Info: Putting any concurrent dvc commit or push operations on hold (use dvc_scontrol release later). Warning: Concurrent dvc operations cause a potential conflict for acquiring ../../../../../../.dvc/tmp/rwlock) and dvc commands (incl. repro) will error out if they detect this.\n",
      "dvc_scontrol: All jobs of lukasd held. To make sure that no other users run DVC commands on this repo use 'dvc_scontrol show commit'.\n",
      "dvc_scontrol: All jobs of lukasd held. To make sure that no other users run DVC commands on this repo use 'dvc_scontrol show push'.\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_training_run_20230721_081756]: DVC stage deps of ex_vit_cifar10_baseline_model_training_run_20230721_081756: ../../config/default/dvc.yaml:ex_vit_cifar10_baseline_model_config_init ../../../../../in/cifar10/original/dvc.yaml:in_original_fetch_cifar10_init\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_training_run_20230721_081756]: DVC stage outs of ex_vit_cifar10_baseline_model_training_run_20230721_081756: ../../../../../../encrypt/ex_vit/cifar10/baseline_model/training/run_20230721_081756/output output\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_training_run_20230721_081756]: Looking for state of DVC dependency ../../config/default/dvc.yaml:ex_vit_cifar10_baseline_model_config_init.\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_training_run_20230721_081756]: No SLURM status (pending/started/complete/failed) set for DVC dependency ../../config/default/dvc.yaml:ex_vit_cifar10_baseline_model_config_init - assuming committed, skipping this dependency.\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_training_run_20230721_081756]: Looking for state of DVC dependency ../../../../../in/cifar10/original/dvc.yaml:in_original_fetch_cifar10_init.\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_training_run_20230721_081756]: No SLURM status (pending/started/complete/failed) set for DVC dependency ../../../../../in/cifar10/original/dvc.yaml:in_original_fetch_cifar10_init - assuming committed, skipping this dependency.\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_training_run_20230721_081756]: Cannot find running/committed stage ex_vit_cifar10_baseline_model_training_run_20230721_081756 - submitting it.\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_training_run_20230721_081756]: Launching asynchronous stage ex_vit_cifar10_baseline_model_training_run_20230721_081756 with SLURM\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_training_run_20230721_081756]: Submit push job for ex_vit_cifar10_baseline_model_training_run_20230721_081756 manually with slurm_enqueue_dvc_push_ex_vit_cifar10_baseline_model_training_run_20230721_081756.sh.\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_training_run_20230721_081756]: Submitted all jobs for stage ex_vit_cifar10_baseline_model_training_run_20230721_081756 (stage: 49288801, cleanup: 49288804, commit: 49288805).\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_training_run_20230721_081756]: All jobs submitted on hold to enable further DVC usage. When ready, use 'scontrol release <job-id1> <job-id2> ...' to selectively unblock invidual jobs or 'dvc_scontrol release (stage|commit|push)' to unblock all jobs of particular type in this DVC repo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: 'encrypt/ex_vit/cifar10/baseline_model/training/run_20230721_081756/output' is empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: 'encrypt/ex_vit/cifar10/baseline_model/training/run_20230721_081756/output' is empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running stage 'config/ex_vit/cifar10/baseline_model/inference/run_20230721_115412/dvc.yaml:ex_vit_cifar10_baseline_model_inference_run_20230721_115412':\n",
      "> dvc_cmd ex_vit_cifar10_baseline_model_inference_run_20230721_115412 slurm_enqueue.sh ex_vit_cifar10_baseline_model_inference_run_20230721_115412 dvc_app.yaml inference encfs_mount_and_run ../../../../../../encrypt /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_inference_run_20230721_115412_2c499e122511_cc38b32792ae ../../../../../../../../../../../../../../tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_inference_run_20230721_115412_2c499e122511_cc38b32792ae/ex_vit/cifar10/baseline_model/inference/run_20230721_115412/output/encfs_out_{MPI_RANK}.log bash -c \"$(git rev-parse --show-toplevel)/examples/ex_vit/inference.py --training-output /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_inference_run_20230721_115412_2c499e122511_cc38b32792ae/ex_vit/cifar10/baseline_model/training/run_20230721_081756/output --inference-input /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_inference_run_20230721_115412_2c499e122511_cc38b32792ae/in/cifar10/original/output --config /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_inference_run_20230721_115412_2c499e122511_cc38b32792ae/ex_vit/cifar10/baseline_model/config/default/output/config.yaml --inference-output /tmp/encfs_25680_async_encfs_dvc_ex_vit_cifar10_baseline_model_inference_run_20230721_115412_2c499e122511_cc38b32792ae/ex_vit/cifar10/baseline_model/inference/run_20230721_115412/output --dry-run\" \n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_inference_run_20230721_115412]: Info: Putting any concurrent dvc commit or push operations on hold (use dvc_scontrol release later). Warning: Concurrent dvc operations cause a potential conflict for acquiring ../../../../../../.dvc/tmp/rwlock) and dvc commands (incl. repro) will error out if they detect this.\n",
      "dvc_scontrol: All jobs of lukasd held. To make sure that no other users run DVC commands on this repo use 'dvc_scontrol show commit'.\n",
      "dvc_scontrol: All jobs of lukasd held. To make sure that no other users run DVC commands on this repo use 'dvc_scontrol show push'.\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_inference_run_20230721_115412]: DVC stage deps of ex_vit_cifar10_baseline_model_inference_run_20230721_115412: ../../config/default/dvc.yaml:ex_vit_cifar10_baseline_model_config_init ../../training/run_20230721_081756/dvc.yaml:ex_vit_cifar10_baseline_model_training_run_20230721_081756 ../../../../../in/cifar10/original/dvc.yaml:in_original_fetch_cifar10_init\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_inference_run_20230721_115412]: DVC stage outs of ex_vit_cifar10_baseline_model_inference_run_20230721_115412: ../../../../../../encrypt/ex_vit/cifar10/baseline_model/inference/run_20230721_115412/output output\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_inference_run_20230721_115412]: Looking for state of DVC dependency ../../config/default/dvc.yaml:ex_vit_cifar10_baseline_model_config_init.\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_inference_run_20230721_115412]: No SLURM status (pending/started/complete/failed) set for DVC dependency ../../config/default/dvc.yaml:ex_vit_cifar10_baseline_model_config_init - assuming committed, skipping this dependency.\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_inference_run_20230721_115412]: Looking for state of DVC dependency ../../training/run_20230721_081756/dvc.yaml:ex_vit_cifar10_baseline_model_training_run_20230721_081756.\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_inference_run_20230721_115412]: Looking for state of DVC dependency ../../../../../in/cifar10/original/dvc.yaml:in_original_fetch_cifar10_init.\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_inference_run_20230721_115412]: No SLURM status (pending/started/complete/failed) set for DVC dependency ../../../../../in/cifar10/original/dvc.yaml:in_original_fetch_cifar10_init - assuming committed, skipping this dependency.\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_inference_run_20230721_115412]: Cannot find running/committed stage ex_vit_cifar10_baseline_model_inference_run_20230721_115412 - submitting it.\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_inference_run_20230721_115412]: Launching asynchronous stage ex_vit_cifar10_baseline_model_inference_run_20230721_115412 with SLURM\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_inference_run_20230721_115412]: Submit push job for ex_vit_cifar10_baseline_model_inference_run_20230721_115412 manually with slurm_enqueue_dvc_push_ex_vit_cifar10_baseline_model_inference_run_20230721_115412.sh.\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_inference_run_20230721_115412]: Submitted all jobs for stage ex_vit_cifar10_baseline_model_inference_run_20230721_115412 (stage: 49288806, cleanup: 49288807, commit: 49288808).\n",
      "slurm_enqueue.sh[ex_vit_cifar10_baseline_model_inference_run_20230721_115412]: All jobs submitted on hold to enable further DVC usage. When ready, use 'scontrol release <job-id1> <job-id2> ...' to selectively unblock invidual jobs or 'dvc_scontrol release (stage|commit|push)' to unblock all jobs of particular type in this DVC repo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: 'encrypt/ex_vit/cifar10/baseline_model/training/run_20230721_081756/output' is empty.\n",
      "WARNING: 'encrypt/ex_vit/cifar10/baseline_model/inference/run_20230721_115412/output' is empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use `dvc commit` and `dvc push` to send your updates to remote storage.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "dvc repro --no-commit --no-lock config/ex_vit/cifar10/baseline_model/inference/${VIT_INF_RUN_LABEL}/dvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e6b615-cd91-4292-acdf-b8e5aeee21f5",
   "metadata": {},
   "source": [
    "The submitted SLURM stages can be monitored with a status file and log files in the `dvc.yaml` directory as well as the tool `dvc_scontrol` as familiar from the [SLURM tutorial](slurm_async_sim_tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "511800fd-c6e4-46b5-8cc2-8ef16dbc0559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dvc_scontrol: DVC stage jobs:\n",
      "           USER           JOBID     REASON       TIME  TIME_LEFT                                                         NAME                                                                                                                           WORK_DIR\n",
      "         lukasd        49288801 JobHeldUse       0:00   12:00:00 dvc_ex_vit_cifar10_baseline_model_training_run_20230721_0817 /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/config/ex_vit/cifar10/baseline_model/training/run_20230721_0817\n",
      "         lukasd        49288806 JobHeldUse       0:00    4:00:00 dvc_ex_vit_cifar10_baseline_model_inference_run_20230721_115 /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/config/ex_vit/cifar10/baseline_model/inference/run_20230721_115\n",
      "dvc_scontrol: DVC commit jobs:\n",
      "           USER           JOBID     REASON       TIME  TIME_LEFT                                                         NAME                                                                                                                           WORK_DIR\n",
      "         lukasd        49288805 JobHeldUse       0:00    4:00:00                                          dvc_op_cc38b32792ae /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/config/ex_vit/cifar10/baseline_model/training/run_20230721_0817\n",
      "         lukasd        49288808 JobHeldUse       0:00    4:00:00                                          dvc_op_cc38b32792ae /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/config/ex_vit/cifar10/baseline_model/inference/run_20230721_115\n",
      "dvc_scontrol: DVC cleanup jobs:\n",
      "           USER           JOBID     REASON       TIME  TIME_LEFT                                                         NAME                                                                                                                           WORK_DIR\n",
      "         lukasd        49288804 Dependency       0:00    4:00:00 dvc_cleanup_ex_vit_cifar10_baseline_model_training_run_20230 /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/config/ex_vit/cifar10/baseline_model/training/run_20230721_0817\n",
      "         lukasd        49288807 Dependency       0:00    4:00:00 dvc_cleanup_ex_vit_cifar10_baseline_model_inference_run_2023 /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/config/ex_vit/cifar10/baseline_model/inference/run_20230721_115\n",
      "dvc_scontrol: DVC push jobs:\n",
      "           USER           JOBID     REASON       TIME  TIME_LEFT                                                         NAME                                                                                                                           WORK_DIR\n"
     ]
    }
   ],
   "source": [
    "!dvc_scontrol show all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d1059e-8bbe-4212-a6d0-2457c3613ae9",
   "metadata": {},
   "source": [
    "As the stage and commit jobs are put on hold in order to enable the submission of more DVC SLURM stages by the user, we have to release them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6188114-319f-42de-9041-a24d9dad43be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dvc_scontrol: Releasing job dvc_ex_vit_cifar10_baseline_model_training_run_20230721_081756_cc38b32792ae[sbatch_dvc_stage_ex_vit_cifar10_baseline_model_training_run_2023072] (reason JobHeldUser) at 49288801.\n",
      "dvc_scontrol: Releasing job dvc_ex_vit_cifar10_baseline_model_inference_run_20230721_115412_cc38b32792ae[sbatch_dvc_stage_ex_vit_cifar10_baseline_model_inference_run_20230] (reason JobHeldUser) at 49288806.\n",
      "dvc_scontrol: Releasing job dvc_op_cc38b32792ae[sbatch_dvc_commit.sh] (reason JobHeldUser) at 49288805.\n",
      "dvc_scontrol: Releasing job dvc_op_cc38b32792ae[sbatch_dvc_commit.sh] (reason JobHeldUser) at 49288808.\n"
     ]
    }
   ],
   "source": [
    "!dvc_scontrol release stage,commit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8fdb1f-116d-4d52-8d08-06f299b69c32",
   "metadata": {},
   "source": [
    "This will enable resource allocation and execution of the application stages. Upon successfull execution, the stage outputs will also be committed. We can now log out from the SLURM cluster and return later to inspect results.\n",
    "\n",
    "For the purpose of this notebook, however, we want to keep monitoring the pipeline on SLURM and wait for the completion of the last job, which is a DVC commit.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77ad1039-2b47-413f-b53f-6e7a01bdea0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring SLURM job 49288808.\n",
      "The SLURM pipeline is still in process.\n",
      "dvc_scontrol: DVC stage jobs:\n",
      "           USER           JOBID     REASON       TIME  TIME_LEFT                                                         NAME                                                                                                                           WORK_DIR\n",
      "         lukasd        49288801       None       0:27   11:59:33 dvc_ex_vit_cifar10_baseline_model_training_run_20230721_0817 /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/config/ex_vit/cifar10/baseline_model/training/run_20230721_0817\n",
      "         lukasd        49288806 Dependency       0:00    4:00:00 dvc_ex_vit_cifar10_baseline_model_inference_run_20230721_115 /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/config/ex_vit/cifar10/baseline_model/inference/run_20230721_115\n",
      "dvc_scontrol: DVC commit jobs:\n",
      "           USER           JOBID     REASON       TIME  TIME_LEFT                                                         NAME                                                                                                                           WORK_DIR\n",
      "         lukasd        49288805 Dependency       0:00    4:00:00                                          dvc_op_cc38b32792ae /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/config/ex_vit/cifar10/baseline_model/training/run_20230721_0817\n",
      "         lukasd        49288808 Dependency       0:00    4:00:00                                          dvc_op_cc38b32792ae /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/config/ex_vit/cifar10/baseline_model/inference/run_20230721_115\n",
      "The SLURM pipeline is still in process.\n",
      "dvc_scontrol: DVC stage jobs:\n",
      "           USER           JOBID     REASON       TIME  TIME_LEFT                                                         NAME                                                                                                                           WORK_DIR\n",
      "         lukasd        49288806       None       0:27    3:59:33 dvc_ex_vit_cifar10_baseline_model_inference_run_20230721_115 /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/config/ex_vit/cifar10/baseline_model/inference/run_20230721_115\n",
      "dvc_scontrol: DVC commit jobs:\n",
      "           USER           JOBID     REASON       TIME  TIME_LEFT                                                         NAME                                                                                                                           WORK_DIR\n",
      "         lukasd        49288805       None       0:27    3:59:33                                          dvc_op_cc38b32792ae /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/config/ex_vit/cifar10/baseline_model/training/run_20230721_0817\n",
      "         lukasd        49288808 Dependency       0:00    4:00:00                                          dvc_op_cc38b32792ae /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/config/ex_vit/cifar10/baseline_model/inference/run_20230721_115\n",
      "The SLURM pipeline is still in process.\n",
      "dvc_scontrol: DVC stage jobs:\n",
      "           USER           JOBID     REASON       TIME  TIME_LEFT                                                         NAME                                                                                                                           WORK_DIR\n",
      "dvc_scontrol: DVC commit jobs:\n",
      "           USER           JOBID     REASON       TIME  TIME_LEFT                                                         NAME                                                                                                                           WORK_DIR\n",
      "         lukasd        49288808       None       0:18    3:59:42                                          dvc_op_cc38b32792ae /scratch/snx3000/lukasd/mitraccel/async-encfs-dvc/examples/data/v3/config/ex_vit/cifar10/baseline_model/inference/run_20230721_115\n",
      "The SLURM pipeline has successfully completed.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# ID of last commit job\n",
    "commit_jobid=$(cat config/ex_vit/cifar10/baseline_model/inference/${VIT_INF_RUN_LABEL}/ex_vit_cifar10_baseline_model_inference_${VIT_INF_RUN_LABEL}.dvc_commit_jobid)\n",
    "../../slurm_wait_for_job.sh ${commit_jobid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d18e7364-2734-4b47-a0d9-19d080938585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mencrypt/in\u001b[00m\n",
      "└── \u001b[01;34mcifar10\u001b[00m\n",
      "    └── \u001b[01;34moriginal\u001b[00m\n",
      "        └── \u001b[01;34moutput\u001b[00m\n",
      "            ├── \u001b[01;34mcifar-10-batches-py\u001b[00m\n",
      "            │   ├── batches.meta\n",
      "            │   ├── data_batch_1\n",
      "            │   ├── data_batch_2\n",
      "            │   ├── data_batch_3\n",
      "            │   ├── data_batch_4\n",
      "            │   ├── data_batch_5\n",
      "            │   ├── readme.html\n",
      "            │   └── test_batch\n",
      "            ├── \u001b[01;31mcifar-10-python.tar.gz\u001b[00m\n",
      "            └── encfs_out_0.log\n",
      "\u001b[01;34mencrypt/ex_vit\u001b[00m\n",
      "└── \u001b[01;34mcifar10\u001b[00m\n",
      "    └── \u001b[01;34mbaseline_model\u001b[00m\n",
      "        ├── \u001b[01;34mconfig\u001b[00m\n",
      "        │   └── \u001b[01;34mdefault\u001b[00m\n",
      "        │       └── \u001b[01;34moutput\u001b[00m\n",
      "        │           ├── config.yaml\n",
      "        │           └── encfs_out_0.log\n",
      "        ├── \u001b[01;34minference\u001b[00m\n",
      "        │   └── \u001b[01;34mrun_20230721_115412\u001b[00m\n",
      "        │       └── \u001b[01;34moutput\u001b[00m\n",
      "        │           ├── encfs_out_0.log\n",
      "        │           └── predicted_labels.pkl\n",
      "        └── \u001b[01;34mtraining\u001b[00m\n",
      "            └── \u001b[01;34mrun_20230721_081756\u001b[00m\n",
      "                └── \u001b[01;34moutput\u001b[00m\n",
      "                    ├── best-weights.pt\n",
      "                    ├── encfs_out_0.log\n",
      "                    ├── encfs_out_1.log\n",
      "                    ├── encfs_out_2.log\n",
      "                    └── encfs_out_3.log\n",
      "\u001b[01;34mconfig/in\u001b[00m\n",
      "└── \u001b[01;34mcifar10\u001b[00m\n",
      "    └── \u001b[01;34moriginal\u001b[00m\n",
      "        ├── dvc_app.yaml\n",
      "        ├── dvc.lock\n",
      "        ├── dvc_sbatch.dvc_commit.49288750.err\n",
      "        ├── dvc_sbatch.dvc_commit.49288750.out\n",
      "        ├── dvc.yaml\n",
      "        ├── in_original_fetch_cifar10_init.dvc_cleanup_jobid\n",
      "        ├── in_original_fetch_cifar10_init.dvc_commit_jobid\n",
      "        ├── in_original_fetch_cifar10_init.dvc_stage_jobid\n",
      "        ├── \u001b[01;34moutput\u001b[00m\n",
      "        │   ├── dvc_sbatch.dvc_in_original_fetch_cifar10_init_cc38b32792ae.49288748.out\n",
      "        │   └── dvc_stage_out.log\n",
      "        ├── \u001b[01;32msbatch_dvc_stage_in_original_fetch_cifar10_init.sh\u001b[00m\n",
      "        └── \u001b[01;32mslurm_enqueue_dvc_push_in_original_fetch_cifar10_init.sh\u001b[00m\n",
      "\u001b[01;34mconfig/ex_vit\u001b[00m\n",
      "└── \u001b[01;34mcifar10\u001b[00m\n",
      "    └── \u001b[01;34mbaseline_model\u001b[00m\n",
      "        ├── \u001b[01;34mconfig\u001b[00m\n",
      "        │   └── \u001b[01;34mdefault\u001b[00m\n",
      "        │       ├── dvc_app.yaml\n",
      "        │       ├── dvc.lock\n",
      "        │       ├── dvc.yaml\n",
      "        │       └── \u001b[01;34moutput\u001b[00m\n",
      "        │           └── dvc_stage_out.log\n",
      "        ├── \u001b[01;34minference\u001b[00m\n",
      "        │   └── \u001b[01;34mrun_20230721_115412\u001b[00m\n",
      "        │       ├── dvc_app.yaml\n",
      "        │       ├── dvc_dag.dot\n",
      "        │       ├── dvc.lock\n",
      "        │       ├── dvc_sbatch.dvc_commit.49288808.err\n",
      "        │       ├── dvc_sbatch.dvc_commit.49288808.out\n",
      "        │       ├── dvc.yaml\n",
      "        │       ├── ex_vit_cifar10_baseline_model_inference_run_20230721_115412.dvc_cleanup_jobid\n",
      "        │       ├── ex_vit_cifar10_baseline_model_inference_run_20230721_115412.dvc_commit_jobid\n",
      "        │       ├── ex_vit_cifar10_baseline_model_inference_run_20230721_115412.dvc_stage_jobid\n",
      "        │       ├── \u001b[01;34moutput\u001b[00m\n",
      "        │       │   ├── dvc_sbatch.dvc_ex_vit_cifar10_baseline_model_inference_run_20230721_115412_cc38b32792ae.49288806.out\n",
      "        │       │   └── dvc_stage_out.log\n",
      "        │       ├── \u001b[01;32msbatch_dvc_stage_ex_vit_cifar10_baseline_model_inference_run_20230721_115412.sh\u001b[00m\n",
      "        │       └── \u001b[01;32mslurm_enqueue_dvc_push_ex_vit_cifar10_baseline_model_inference_run_20230721_115412.sh\u001b[00m\n",
      "        └── \u001b[01;34mtraining\u001b[00m\n",
      "            └── \u001b[01;34mrun_20230721_081756\u001b[00m\n",
      "                ├── dvc_app.yaml\n",
      "                ├── dvc.lock\n",
      "                ├── dvc_sbatch.dvc_commit.49288805.err\n",
      "                ├── dvc_sbatch.dvc_commit.49288805.out\n",
      "                ├── dvc.yaml\n",
      "                ├── ex_vit_cifar10_baseline_model_training_run_20230721_081756.dvc_cleanup_jobid\n",
      "                ├── ex_vit_cifar10_baseline_model_training_run_20230721_081756.dvc_commit_jobid\n",
      "                ├── ex_vit_cifar10_baseline_model_training_run_20230721_081756.dvc_stage_jobid\n",
      "                ├── \u001b[01;34moutput\u001b[00m\n",
      "                │   ├── dvc_sbatch.dvc_ex_vit_cifar10_baseline_model_training_run_20230721_081756_cc38b32792ae.49288801.out\n",
      "                │   └── dvc_stage_out.log\n",
      "                ├── \u001b[01;32msbatch_dvc_stage_ex_vit_cifar10_baseline_model_training_run_20230721_081756.sh\u001b[00m\n",
      "                └── \u001b[01;32mslurm_enqueue_dvc_push_ex_vit_cifar10_baseline_model_training_run_20230721_081756.sh\u001b[00m\n",
      "\n",
      "29 directories, 60 files\n"
     ]
    }
   ],
   "source": [
    "!tree {encrypt,config}/{in,ex_vit}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3533b106-1d54-461c-8b24-c7921c5eeb68",
   "metadata": {},
   "source": [
    "We will convince ourselves that the predicted labels are encrypted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfc9ad95-7590-4228-a31e-aac319b729fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error unpickling the file at encrypt/ex_vit/cifar10/baseline_model/inference/run_20230721_115412/output/predicted_labels.pkl:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_6327/3340629226.py\", line 6, in unpickle_and_print_labels\n",
      "    predicted_labels = pickle.load(f)\n",
      "_pickle.UnpicklingError: invalid load key, '\\x1a'.\n"
     ]
    }
   ],
   "source": [
    "os.environ['VIT_PREDICTED_LABELS'] = f\"ex_vit/cifar10/baseline_model/inference/{os.environ['VIT_INF_RUN_LABEL']}/output/predicted_labels.pkl\"\n",
    "\n",
    "def unpickle_and_print_labels(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'rb') as f:\n",
    "            predicted_labels = pickle.load(f)\n",
    "        print(\"Successfully unpickled labels:\")\n",
    "        print(predicted_labels)\n",
    "    except:\n",
    "        print(f\"Error unpickling the file at {filepath}:\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "unpickle_and_print_labels(os.path.join('encrypt', os.environ['VIT_PREDICTED_LABELS']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355507b7-efbc-4700-a96f-238cf2d20b1f",
   "metadata": {},
   "source": [
    "and that they can be read through the EncFS-layer (only for exposition, not to be performed on confidential data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd7f02d0-9e40-4c63-bfa2-048ad688dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "!encfs_mount_and_run encrypt ${ENCFS_DECRYPT_DIR} /dev/null cp ${ENCFS_DECRYPT_DIR}/${VIT_PREDICTED_LABELS} predicted_labels.pkl >/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e04720ae-74ec-407c-abf5-186fe0abe0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully unpickled labels:\n",
      "[array([7, 6, 7, 7])]\n"
     ]
    }
   ],
   "source": [
    "unpickle_and_print_labels('predicted_labels.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1287334c-4367-4c02-8415-89a5500fa262",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm predicted_labels.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ae941b-fda2-4a23-8970-0108e483140a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
